#!/usr/bin/env python3
"""
Gemini Chat CLI - å¤šè½®ä¼šè¯å‘½ä»¤è¡Œå·¥å…·
æ”¯æŒå¤šç§åç«¯ï¼šæœ¬åœ°Gemini Reverse APIã€NexusAIç­‰

ç”¨æ³•:
    gchat                    # äº¤äº’å¼å¤šè½®ä¼šè¯ï¼ˆé»˜è®¤ gemini-3-pro-previewï¼‰
    gflashchat               # ä½¿ç”¨ gemini-3-flash-preview
    gchat -m flash3          # ä½¿ç”¨ flash3 æ¨¡å‹
    gchat -p "ä½ å¥½"          # å•æ¬¡æé—®
    gchat --backend nexus    # ä½¿ç”¨NexusAIåç«¯
    gchat --list-models      # åˆ—å‡ºå¯ç”¨æ¨¡å‹
"""

import argparse
import json
import os
import sys
import subprocess
import readline  # æ”¯æŒå†å²è®°å½•å’Œè¡Œç¼–è¾‘
import base64
import mimetypes
import re
import shlex
import shutil
import signal
import glob as glob_module
import threading
import time
from pathlib import Path

from wcwidth import wcswidth, wcwidth


_CTRL_CHARS_RE = re.compile(r"[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]")


def sanitize_terminal_paste(text: str) -> str:
    """æ¸…ç†ç»ˆç«¯ç²˜è´´å¯èƒ½å¸¦æ¥çš„æ§åˆ¶å­—ç¬¦/è½¬ä¹‰åºåˆ—ã€‚

    ç›®çš„ï¼šé¿å…æŠŠä¸å¯è§æ§åˆ¶å­—ç¬¦å¸¦è¿› prompt / API è¯·æ±‚ï¼Œæˆ–è§¦å‘å¿«æ·é”®è¡Œä¸ºã€‚
    """
    if not text:
        return text

    # ç»Ÿä¸€æ¢è¡Œ
    text = text.replace("\r\n", "\n").replace("\r", "\n")

    # å¸¸è§çš„ bracketed paste åŒ…è£¹
    text = text.replace("\x1b[200~", "").replace("\x1b[201~", "")

    # ç§»é™¤ä¸å¯è§æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™æ¢è¡Œ/åˆ¶è¡¨ç¬¦ï¼‰
    return _CTRL_CHARS_RE.sub("", text)

try:
    from prompt_toolkit import prompt as pt_prompt
    from prompt_toolkit.formatted_text import ANSI as PTANSI, HTML
    from prompt_toolkit.history import FileHistory
    from prompt_toolkit.key_binding import KeyBindings
except Exception:
    pt_prompt = None
    PTANSI = None
    HTML = None
    FileHistory = None
    KeyBindings = None

# åç«¯é…ç½®
BACKENDS = {
    "google": {
        "url": "https://google-api.aihang365.com/v1/chat/completions",
        "name": "Google API (å†…éƒ¨æœåŠ¡ï¼Œæ”¯æŒFunction Calling)",
        "supports_tools": True,
    },
    "local": {
        "url": "http://82.29.54.80:8100/v1/chat/completions",
        "name": "Gemini Reverse API (æœ¬åœ°)",
        "supports_tools": False,
    },
    "nexus": {
        "url": "https://nexusai.aihang365.com/v1/chat/completions",
        "key": "GeminiReverseTest2025abcdefghijklmnopqrstuvwx",
        "name": "NexusAI",
        "supports_tools": False,
    },
    "official": {
        "url": "https://gemini-official.aihang365.com/v1beta/models/{model}:generateContent",
        "key": os.environ.get("GEMINI_API_KEY", ""),
        "name": "Google Official API (via US Proxy)",
        "supports_tools": True,
        "default_model": "gemini-2.5-flash-lite",  # æœ‰å…è´¹é¢åº¦ä¸”æ”¯æŒtools
    },
}

# å®˜æ–¹APIæ¨¡å‹æ˜ å°„ (é€†å‘æ¨¡å‹å -> å®˜æ–¹æ¨¡å‹å)
OFFICIAL_MODEL_MAP = {
    "gemini-3-flash-preview": "gemini-2.5-flash-lite",
    "gemini-2.5-flash": "gemini-2.5-flash-lite",
    "gemini-2.5-pro": "gemini-2.5-flash-lite",  # proæ²¡å…è´¹é¢åº¦ï¼Œé™çº§åˆ°flash-lite
    "gemini-3.0-pro": "gemini-2.5-flash-lite",
}

# æ¨¡å‹åˆ«å
MODEL_ALIASES = {
    "pro3": "gemini-3-pro-preview",  # â­ gchat é»˜è®¤
    "flash3": "gemini-3-flash-preview",  # gflashchat é»˜è®¤
    "flash": "gemini-3-flash-preview",
    "flash2": "gemini-2.5-flash",  # æ—§ç‰ˆ Flash
    "pro": "gemini-2.5-pro",
    "3": "gemini-3.0-pro",
}

# æ¨¡å‹é™çº§æ˜ å°„ (gemini-3 å¤±è´¥æ—¶é™çº§åˆ° gemini-2.5)
FALLBACK_MODELS = {
    "gemini-3-pro-preview": "gemini-2.5-pro",
    "gemini-3-flash-preview": "gemini-2.5-flash",
}

# é¢„å®šä¹‰çš„å¸¸ç”¨å·¥å…·
BUILTIN_TOOLS = {
    "weather": {
        "name": "get_weather",
        "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "åŸå¸‚åç§°ï¼Œå¦‚'åŒ—äº¬'ã€'ä¸Šæµ·'"}
            },
            "required": ["city"]
        }
    },
    "search": {
        "name": "web_search",
        "description": "æœç´¢ç½‘é¡µè·å–ä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"}
            },
            "required": ["query"]
        }
    },
    "calculator": {
        "name": "calculate",
        "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—",
        "parameters": {
            "type": "object",
            "properties": {
                "expression": {"type": "string", "description": "æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚'2+2'ã€'sqrt(16)'"}
            },
            "required": ["expression"]
        }
    },
    "bash": {
        "name": "run_bash",
        "description": "æ‰§è¡Œbashå‘½ä»¤",
        "parameters": {
            "type": "object",
            "properties": {
                "command": {"type": "string", "description": "è¦æ‰§è¡Œçš„bashå‘½ä»¤"}
            },
            "required": ["command"]
        }
    },
    "write": {
        "name": "write_file",
        "description": "å°†å†…å®¹å†™å…¥æ–‡ä»¶ã€‚å½“ç”¨æˆ·è¦æ±‚ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ 'poem.md'ã€'output.txt'"},
                "content": {"type": "string", "description": "è¦å†™å…¥çš„å†…å®¹"}
            },
            "required": ["path", "content"]
        }
    },
    "read": {
        "name": "read_file",
        "description": "è¯»å–æ–‡ä»¶å†…å®¹ã€‚å½“ç”¨æˆ·è¦æ±‚åˆ†ææˆ–æŸ¥çœ‹æ–‡ä»¶æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„"}
            },
            "required": ["path"]
        }
    },
}

# é¢œè‰²è¾“å‡º
class Color:
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    DIM = '\033[2m'
    BOLD = '\033[1m'
    END = '\033[0m'

def colored(text, color):
    """è¿”å›å¸¦é¢œè‰²çš„æ–‡æœ¬"""
    if not sys.stdout.isatty():
        return text
    return f"{color}{text}{Color.END}"


ANSI_ESCAPE_RE = re.compile(r"\x1b\[[0-9;]*m")


def readline_safe_prompt(prompt: str) -> str:
    """è®©å¸¦ ANSI é¢œè‰²çš„ prompt åœ¨ readline ä¸‹ä¸ç ´åæ¢è¡Œ/å…‰æ ‡å®šä½ã€‚

    Python çš„ readline ä¼šæŠŠ ANSI æ§åˆ¶åºåˆ—ä¹Ÿè®¡å…¥é•¿åº¦ï¼Œå¯¼è‡´é•¿æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œæ—¶å…‰æ ‡é”™ä½ã€‚
    ç”¨ \001/\002 åŒ…è£¹ä¸å¯è§å­—ç¬¦ç‰‡æ®µå¯ä¿®å¤è¯¥é—®é¢˜ã€‚
    """
    if not sys.stdin.isatty():
        return prompt

    try:
        # è‹¥ readline ä¸å¯ç”¨ï¼Œç›´æ¥è¿”å›
        import readline as _  # noqa: F401
    except Exception:
        return prompt

    def _wrap(match: re.Match[str]) -> str:
        return f"\001{match.group(0)}\002"

    return ANSI_ESCAPE_RE.sub(_wrap, prompt)


def get_gchat_dir() -> str:
    """è·å–gchatæ•°æ®ç›®å½•ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º"""
    home = os.path.expanduser('~')
    gchat_dir = os.path.join(home, '.gchat')
    os.makedirs(gchat_dir, exist_ok=True)
    return gchat_dir

def get_sessions_dir() -> str:
    """è·å–ä¼šè¯å†å²ç›®å½•"""
    sessions_dir = os.path.join(get_gchat_dir(), 'sessions')
    os.makedirs(sessions_dir, exist_ok=True)
    return sessions_dir

def get_input_history_path() -> str:
    return os.path.join(get_gchat_dir(), 'input_history')


def print_box(title: str, content: str) -> None:
    width = shutil.get_terminal_size((100, 20)).columns
    width = max(60, min(width, 140))

    label = f"[{title}]"
    top = f"â”Œ{label}{'â”€' * max(1, width - 2 - len(label))}â”"
    bottom = f"â””{'â”€' * (width - 2)}â”˜"
    print(colored(top, Color.CYAN))

    def _wrap_display(raw: str, max_w: int) -> list[str]:
        if raw == "":
            return [""]

        out: list[str] = []
        buf: list[str] = []
        cur_w = 0
        for ch in raw.replace('\t', '    '):
            ch_w = wcwidth(ch)
            if ch_w < 0:
                ch_w = 0
            if cur_w + ch_w > max_w and buf:
                out.append(''.join(buf))
                buf = [ch]
                cur_w = ch_w
                continue
            buf.append(ch)
            cur_w += ch_w
        out.append(''.join(buf))
        return out

    inner_w = width - 4
    lines = content.splitlines() or [""]
    for raw in lines:
        for wline in _wrap_display(raw, inner_w):
            line_w = wcswidth(wline)
            if line_w < 0:
                line_w = len(wline)
            pad = " " * max(0, inner_w - line_w)
            print(colored("â”‚ ", Color.CYAN) + wline + pad + colored(" â”‚", Color.CYAN))

    print(colored(bottom, Color.CYAN))


def is_image_file(path: Path) -> bool:
    if not path.is_file():
        return False

    suffix = path.suffix.lower().lstrip('.')
    return suffix in {
        'png', 'jpg', 'jpeg', 'gif', 'webp', 'bmp', 'tiff', 'tif', 'heic'
    }


def encode_image_to_data_url(path: Path) -> str:
    mime, _ = mimetypes.guess_type(str(path))
    if not mime:
        # å°½é‡ç»™ä¸€ä¸ªåˆç†é»˜è®¤
        mime = f"image/{path.suffix.lower().lstrip('.')}" if path.suffix else "application/octet-stream"

    data = path.read_bytes()
    b64 = base64.b64encode(data).decode('ascii')
    return f"data:{mime};base64,{b64}"


def extract_local_image_paths(text: str) -> tuple[str, list[Path]]:
    """ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æœ¬åœ°å›¾ç‰‡è·¯å¾„ï¼ˆç”¨äºæ‹–æ‹½æ–‡ä»¶åˆ°ç»ˆç«¯åœºæ™¯ï¼‰ã€‚

    - ä»…å½“ token æŒ‡å‘çœŸå®å­˜åœ¨çš„æ–‡ä»¶ä¸”æ‰©å±•åæ˜¯å›¾ç‰‡æ—¶æ‰è®¤å®šä¸ºå›¾ç‰‡ã€‚
    - è¿”å›ï¼šç§»é™¤å›¾ç‰‡è·¯å¾„åçš„æ–‡æœ¬ + å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    """
    # ä»…å¯¹å•è¡Œè¾“å…¥åšè‡ªåŠ¨è¯†åˆ«ï¼Œé¿å…ç ´åç”¨æˆ·å¤šè¡Œæ–‡æœ¬æ ¼å¼
    if '\n' in text:
        return text, []

    try:
        tokens = shlex.split(text, posix=True)
    except ValueError:
        # å¼•å·ä¸é…å¯¹ç­‰æƒ…å†µï¼šä¿å®ˆå¤„ç†ï¼Œä¸è‡ªåŠ¨æå–
        return text, []

    image_paths: list[Path] = []
    remaining: list[str] = []
    for tok in tokens:
        p = Path(tok).expanduser()
        if is_image_file(p):
            image_paths.append(p)
        else:
            remaining.append(tok)

    cleaned_text = ' '.join(remaining).strip()
    return cleaned_text, image_paths


def normalize_messages_for_api(messages: list[dict]) -> list[dict]:
    """æŠŠæœ¬åœ° message ç»“æ„è½¬æ¢ä¸º OpenAI å…¼å®¹ payloadã€‚

    æ”¯æŒ content ä¸ºï¼š
    - str
    - list[{type:'text', text:'...'} | {type:'image_file', path:'...'}]
    """
    out: list[dict] = []
    for msg in messages:
        content = msg.get('content')
        if isinstance(content, list):
            parts: list[dict] = []
            for part in content:
                if part.get('type') == 'text':
                    text = part.get('text', '')
                    if text:
                        parts.append({"type": "text", "text": text})
                elif part.get('type') == 'image_file':
                    path_str = part.get('path')
                    if not path_str:
                        continue
                    p = Path(path_str).expanduser()
                    if not is_image_file(p):
                        continue
                    parts.append({
                        "type": "image_url",
                        "image_url": {"url": encode_image_to_data_url(p)},
                    })
                elif part.get('type') == 'image_url':
                    # å…¼å®¹å·²æ˜¯ OpenAI æ ¼å¼çš„å†å²è®°å½•
                    image_url = part.get('image_url')
                    if isinstance(image_url, dict) and image_url.get('url'):
                        parts.append({"type": "image_url", "image_url": {"url": image_url["url"]}})
                else:
                    # æœªçŸ¥ part ç±»å‹ï¼šå¿½ç•¥
                    continue

            # å¦‚æœ parts ä¸ºç©ºï¼Œè‡³å°‘ç»™ä¸€ä¸ªç©ºæ–‡æœ¬ï¼Œé¿å…éƒ¨åˆ†åç«¯æŠ¥é”™
            if not parts:
                parts = [{"type": "text", "text": ""}]

            out.append({"role": msg.get('role'), "content": parts})
        else:
            out.append({"role": msg.get('role'), "content": content})

    return out


class StatusSpinner:
    """è¯·æ±‚çŠ¶æ€æ˜¾ç¤ºå™¨ - Claude Code é£æ ¼"""
    WORDS = ["Thinking", "Processing", "Generating", "Working"]

    def __init__(self):
        self._stop = threading.Event()
        self._thread = None
        self._start_time = 0
        self._char_idx = 0
        self._word_idx = 0

    def _animate(self):
        chars = ["Â·", ":", "Â·"]
        while not self._stop.is_set():
            elapsed = int(time.time() - self._start_time)
            if elapsed < 60:
                time_str = f"{elapsed}s"
            else:
                time_str = f"{elapsed // 60}m {elapsed % 60}s"

            word = self.WORDS[self._word_idx % len(self.WORDS)]
            char = chars[self._char_idx % len(chars)]

            status = f"\r\033[K{colored('*', Color.YELLOW)} {word}{char * 3} {colored(f'(ctrl+c to interrupt Â· {time_str})', Color.DIM)}"
            sys.stdout.write(status)
            sys.stdout.flush()

            self._char_idx += 1
            if self._char_idx % 10 == 0:
                self._word_idx += 1
            self._stop.wait(0.15)

    def start(self):
        self._start_time = time.time()
        self._stop.clear()
        self._char_idx = 0
        self._word_idx = 0
        self._thread = threading.Thread(target=self._animate, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread:
            self._thread.join(timeout=0.5)
        sys.stdout.write("\r\033[K")
        sys.stdout.flush()


TIPS = [
    "git commit -m 'fix' åå‘ç°è¿˜æœ‰ bugï¼Œè¿™æ˜¯å®¿å‘½",
    "ä»£ç èƒ½è·‘å°±ä¸è¦åŠ¨ï¼Œé™¤éä½ æƒ³åŠ ç­",
    "æ²¡æœ‰ä»€ä¹ˆæ˜¯é‡å¯è§£å†³ä¸äº†çš„",
    "ä»Šå¤©å†™çš„ä»£ç ï¼Œæ˜å¤©å°±çœ‹ä¸æ‡‚äº†",
    "ä¸å…¶ä¼˜åŒ–ä»£ç ï¼Œä¸å¦‚ä¼˜åŒ–éœ€æ±‚",
    "deadline æ˜¯ç¬¬ä¸€ç”Ÿäº§åŠ›",
    "å¥½ä»£ç è‡ªå·±ä¼šè¯´è¯ï¼Œåä»£ç éœ€è¦æ³¨é‡Š",
    "å…ˆè®©å®ƒè·‘ï¼Œå†è®©å®ƒå¯¹ï¼Œæœ€åè®©å®ƒå¿«",
    "ä¸€ä¸ª TODO æ”¾ä¸‰å¹´ï¼Œå°±æˆäº† TODON'T",
    "If it works, don't touch it",
    "99 ä¸ª bug ä¿®å®Œï¼Œè¿˜å‰© 127 ä¸ª",
    "ç¨‹åºå‘˜æœ€è®¨åŒçš„ä¸¤ä»¶äº‹ï¼šå†™æ³¨é‡Šå’Œæ²¡æ³¨é‡Š",
    "è¿™æ®µä»£ç ä¸ºä»€ä¹ˆèƒ½è·‘ï¼Ÿåˆ«é—®ï¼Œé—®å°±æ˜¯ç„å­¦",
    "rm -rf / ä¸€æ—¶çˆ½ï¼Œä¸€ç›´ rm ä¸€ç›´çˆ½ï¼Ÿ",
    "ä½ çš„ä»£ç ä¸æ˜¯å±å±±ï¼Œæ˜¯å±å–œé©¬æ‹‰é›…",
    "Talk is cheap, show me the code",
    "It works on my machine",
    "æ°¸è¿œä¸è¦ç›¸ä¿¡ç”¨æˆ·è¾“å…¥",
    "å¤åˆ¶ç²˜è´´ï¼Œç¨‹åºå‘˜çš„æ ¸å¿ƒç«äº‰åŠ›",
    "å†™ä»£ç ä¸€æ—¶çˆ½ï¼Œé‡æ„ç«è‘¬åœº",
]

def get_tip():
    """æ ¹æ®æ—¶é—´æˆ³é€‰æ‹©æ®µå­ï¼Œæ¯æ¬¡å¯åŠ¨ä¸åŒ"""
    idx = int(time.time()) % len(TIPS)
    return TIPS[idx]


def print_header():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    print(colored("  gchat", Color.BOLD + Color.MAGENTA) + colored(" v5.0", Color.DIM) + colored("  nexusai.aihang365.com", Color.DIM))
    print(colored(f"  {get_tip()}", Color.DIM))
    print()

def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯ - Claude Code é£æ ¼"""
    sections = [
        ("Commands", [
            ("/help", "show help"),
            ("/quit", "exit (auto-save)"),
            ("/clear", "clear chat history"),
            ("/history", "show chat history"),
        ]),
        ("Files", [
            ("/read <file>", "read file for AI analysis"),
            ("/write <file>", "save last AI reply to file"),
            ("/img <path>", "analyze image"),
        ]),
        ("Sessions", [
            ("/sessions", "list saved sessions"),
            ("/save <file>", "save chat manually"),
            ("/load <file>", "load chat"),
        ]),
        ("Settings", [
            ("/model <name>", "switch model (flash/pro/pro3)"),
            ("/backend <name>", "switch backend"),
            ("/stream", "toggle streaming"),
            ("/mode [box]", "toggle input mode"),
        ]),
    ]

    print()
    for section_name, items in sections:
        print(colored(f"  {section_name}", Color.BOLD))
        for cmd, desc in items:
            print(colored(f"    {cmd:<18}", Color.CYAN) + colored(desc, Color.DIM))
        print()

    print(colored("  Shortcuts", Color.BOLD))
    print(colored("    Ctrl+C", Color.CYAN) + colored("            save & continue", Color.DIM))
    print(colored("    Ctrl+D", Color.CYAN) + colored("            exit (auto-save)", Color.DIM))
    print()
    print(colored(f"  Storage: ~/.gchat/sessions/", Color.DIM))
    print()

def official_api_request(messages, model, tools=None, api_key=None):
    """ä½¿ç”¨Googleå®˜æ–¹APIå‘é€è¯·æ±‚ï¼ˆæ”¯æŒFunction Callingï¼‰"""
    if not api_key:
        api_key = os.environ.get("GEMINI_API_KEY", "")

    if not api_key:
        return None, "[é”™è¯¯] æœªè®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡\nè®¾ç½®æ–¹æ³•: export GEMINI_API_KEY='your-api-key'"

    # æ˜ å°„åˆ°å®˜æ–¹æ¨¡å‹å
    official_model = OFFICIAL_MODEL_MAP.get(model, "gemini-2.5-flash-lite")

    # æ„å»ºå®˜æ–¹APIæ ¼å¼çš„è¯·æ±‚
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{official_model}:generateContent?key={api_key}"

    # è½¬æ¢æ¶ˆæ¯æ ¼å¼ (OpenAI -> Gemini)
    contents = []
    for msg in messages:
        role = "user" if msg["role"] == "user" else "model"
        content = msg.get("content", "")
        if isinstance(content, str):
            contents.append({"role": role, "parts": [{"text": content}]})
        elif isinstance(content, list):
            parts = []
            for part in content:
                if part.get("type") == "text":
                    parts.append({"text": part.get("text", "")})
            if parts:
                contents.append({"role": role, "parts": parts})

    payload = {"contents": contents}

    # æ·»åŠ å·¥å…·å®šä¹‰
    if tools:
        payload["tools"] = [{"function_declarations": tools}]

    curl_cmd = [
        'curl', '-s', '-X', 'POST', url,
        '-H', 'Content-Type: application/json',
        '--max-time', '60',
        '-d', json.dumps(payload)
    ]

    try:
        result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=65)

        if result.returncode != 0:
            return None, f"[curlé”™è¯¯ {result.returncode}]: {result.stderr}"

        response_data = json.loads(result.stdout)

        # æ£€æŸ¥é”™è¯¯
        if "error" in response_data:
            error = response_data["error"]
            return None, f"[APIé”™è¯¯]: {error.get('message', json.dumps(error))}"

        # è§£æå“åº”
        candidates = response_data.get("candidates", [])
        if not candidates:
            return None, "[é”™è¯¯] æ— å“åº”å†…å®¹"

        content = candidates[0].get("content", {})
        parts = content.get("parts", [])

        for part in parts:
            # æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°è°ƒç”¨
            if "functionCall" in part:
                fc = part["functionCall"]
                return {
                    "type": "function_call",
                    "name": fc.get("name"),
                    "args": fc.get("args", {})
                }, None
            # æ™®é€šæ–‡æœ¬å“åº”
            if "text" in part:
                return {"type": "text", "content": part["text"]}, None

        return None, "[é”™è¯¯] æ— æ³•è§£æå“åº”"

    except subprocess.TimeoutExpired:
        return None, "[è¶…æ—¶]: å®˜æ–¹APIè¯·æ±‚è¶…è¿‡60ç§’"
    except json.JSONDecodeError as e:
        return None, f"[JSONè§£æé”™è¯¯]: {e}"
    except Exception as e:
        return None, f"[é”™è¯¯]: {e}"


def openai_tools_request(messages, model, tools, backend_config, retry=2):
    """å‘é€å¸¦å·¥å…·çš„è¯·æ±‚ï¼ˆOpenAI æ ¼å¼ï¼Œç”¨äº google åç«¯ï¼‰"""
    url = backend_config["url"]

    # è½¬æ¢å·¥å…·æ ¼å¼
    openai_tools = []
    for tool in tools:
        openai_tools.append({
            "type": "function",
            "function": {
                "name": tool["name"],
                "description": tool.get("description", ""),
                "parameters": tool.get("parameters", {"type": "object", "properties": {}})
            }
        })

    payload = {
        "model": model,
        "messages": normalize_messages_for_api(messages),
        "tools": openai_tools
    }

    curl_cmd = [
        'curl', '-s', '-X', 'POST', url,
        '-H', 'Content-Type: application/json',
        '--max-time', '120',
        '-d', json.dumps(payload)
    ]

    try:
        result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=125)

        if result.returncode != 0:
            return None, f"[curlé”™è¯¯ {result.returncode}]: {result.stderr}"

        response_data = json.loads(result.stdout)

        if "error" in response_data:
            return None, f"[APIé”™è¯¯]: {response_data['error'].get('message', str(response_data['error']))}"

        choice = response_data.get("choices", [{}])[0]
        message = choice.get("message", {})

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if "tool_calls" in message and message["tool_calls"]:
            tc = message["tool_calls"][0]
            func = tc.get("function", {})
            return {
                "type": "function_call",
                "name": func.get("name"),
                "args": json.loads(func.get("arguments", "{}"))
            }, None

        # æ™®é€šæ–‡æœ¬å“åº”
        content = message.get("content", "")
        if content:
            return {"type": "text", "content": content}, None

        return None, "[é”™è¯¯] æ— æ³•è§£æå“åº”"

    except subprocess.TimeoutExpired:
        return None, "[è¶…æ—¶]: è¯·æ±‚è¶…è¿‡120ç§’"
    except json.JSONDecodeError as e:
        return None, f"[JSONè§£æé”™è¯¯]: {e}\nå“åº”: {result.stdout[:300]}"
    except Exception as e:
        return None, f"[é”™è¯¯]: {e}"


def chat_request(messages, model, backend_config, retry=2, debug=False):
    """å‘é€èŠå¤©è¯·æ±‚ï¼ˆä½¿ç”¨curlï¼Œå…¼å®¹æ€§æœ€å¥½ï¼‰"""
    url = backend_config["url"]
    payload = {
        "model": model,
        "messages": normalize_messages_for_api(messages),
    }

    # æ„å»ºcurlå‘½ä»¤
    curl_cmd = [
        'curl', '-X', 'POST', url,
        '-H', 'Content-Type: application/json',
        '--max-time', '120',
        '--retry', str(retry),  # è‡ªåŠ¨é‡è¯•
        '--retry-delay', '2',    # é‡è¯•é—´éš”2ç§’
        '--connect-timeout', '30'  # è¿æ¥è¶…æ—¶30ç§’
    ]

    # è°ƒè¯•æ¨¡å¼æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    if not debug:
        curl_cmd.insert(1, '-s')  # é™é»˜æ¨¡å¼

    # å¦‚æœæœ‰API keyï¼Œæ·»åŠ Authorization header
    if "key" in backend_config:
        curl_cmd.extend(['-H', f'Authorization: Bearer {backend_config["key"]}'])

    # æ·»åŠ è¯·æ±‚ä½“
    curl_cmd.extend(['-d', json.dumps(payload)])

    try:
        # æ‰§è¡Œcurlå‘½ä»¤
        result = subprocess.run(
            curl_cmd,
            capture_output=True,
            text=True,
            timeout=125
        )

        if result.returncode != 0:
            stderr_msg = result.stderr.strip() if result.stderr else "ç½‘ç»œè¿æ¥å¤±è´¥"

            # é’ˆå¯¹ curl 35 é”™è¯¯ç»™å‡ºå…·ä½“å»ºè®®
            if result.returncode == 35:
                return (
                    f"[SSL/TLSé”™è¯¯ 35]: {stderr_msg}\n\n"
                    f"å¯èƒ½åŸå› :\n"
                    f"1. ç½‘ç»œç¯å¢ƒé—®é¢˜ï¼ˆWiFiä¸ç¨³å®šã€VPNå¹²æ‰°ï¼‰\n"
                    f"2. DNSè§£æé—®é¢˜\n"
                    f"3. é˜²ç«å¢™/å®‰å…¨è½¯ä»¶é˜»æ­¢\n\n"
                    f"å»ºè®®:\n"
                    f"- é‡è¯•å‡ æ¬¡ï¼ˆå¯èƒ½æ˜¯ç¬æ—¶ç½‘ç»œæ³¢åŠ¨ï¼‰\n"
                    f"- åˆ‡æ¢ç½‘ç»œï¼ˆWiFi â†’ æœ‰çº¿ æˆ– æ‰‹æœºçƒ­ç‚¹ï¼‰\n"
                    f"- å°è¯•: curl -v https://nexusai.aihang365.com\n"
                    f"- æˆ–ä½¿ç”¨æœ¬åœ°åç«¯: gchat -b local"
                )

            return f"[curlé”™è¯¯ {result.returncode}]: {stderr_msg}\næç¤º: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"

        # è§£æJSONå“åº”
        response_data = json.loads(result.stdout)

        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "error" in response_data:
            error = response_data["error"]
            error_msg = error.get("message", "")
            error_type = error.get("type", "")
            error_code = error.get("code", "")

            # æ„å»ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
            if error_msg:
                return f"[APIé”™è¯¯]: {error_msg}"
            elif error_type or error_code:
                return f"[APIé”™è¯¯]: {error_type or error_code}\nè¯¦æƒ…: {json.dumps(error, ensure_ascii=False)}"
            else:
                return f"[APIé”™è¯¯]: {json.dumps(error, ensure_ascii=False)}"

        # è¿”å›AIå›å¤
        return response_data["choices"][0]["message"]["content"]

    except subprocess.TimeoutExpired:
        return f"[è¶…æ—¶]: è¯·æ±‚è¶…è¿‡120ç§’"
    except json.JSONDecodeError as e:
        return f"[JSONè§£æé”™è¯¯]: {str(e)}\nå“åº”: {result.stdout[:200]}"
    except Exception as e:
        return f"[é”™è¯¯]: {str(e)}"

def resolve_model(model_input):
    """è§£ææ¨¡å‹åç§°"""
    return MODEL_ALIASES.get(model_input, model_input)


def chat_request_with_fallback(messages, model, backend_config, retry=2, debug=False):
    """å‘é€èŠå¤©è¯·æ±‚ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°å¤‡ç”¨æ¨¡å‹"""
    # ç¬¬ä¸€æ¬¡å°è¯•ï¼šä½¿ç”¨ä¸»æ¨¡å‹
    response = chat_request(messages, model, backend_config, retry=retry, debug=debug)

    # æ£€æŸ¥æ˜¯å¦å¤±è´¥ï¼ˆé”™è¯¯å“åº”ä»¥ [ å¼€å¤´ï¼‰
    if response.startswith("[") and model in FALLBACK_MODELS:
        fallback_model = FALLBACK_MODELS[model]
        print(f"\nâš ï¸  {model} è¯·æ±‚å¤±è´¥ï¼Œé™çº§åˆ° {fallback_model}...")
        response = chat_request(messages, fallback_model, backend_config, retry=retry, debug=debug)
        if not response.startswith("["):
            print(f"âœ… é™çº§æˆåŠŸï¼Œä½¿ç”¨ {fallback_model} å“åº”\n")

    return response


def chat_request_stream(messages, model, backend_config, debug=False, show_spinner=True):
    """æµå¼å‘é€èŠå¤©è¯·æ±‚ï¼Œå…¼å®¹ SSE æµå’Œå®Œæ•´ JSON å“åº”"""
    url = backend_config["url"]
    payload = {
        "model": model,
        "messages": normalize_messages_for_api(messages),
        "stream": True,
    }

    # æ„å»ºcurlå‘½ä»¤
    curl_cmd = [
        'curl', '-X', 'POST', url,
        '-H', 'Content-Type: application/json',
        '-H', 'Accept: text/event-stream',
        '--max-time', '300',
        '--connect-timeout', '30',
        '-N',  # ç¦ç”¨ç¼“å†²
    ]

    if not debug:
        curl_cmd.insert(1, '-s')

    if "key" in backend_config:
        curl_cmd.extend(['-H', f'Authorization: Bearer {backend_config["key"]}'])

    curl_cmd.extend(['-d', json.dumps(payload)])

    spinner = StatusSpinner() if show_spinner else None

    try:
        if spinner:
            spinner.start()

        process = subprocess.Popen(
            curl_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1,
        )

        full_response = ""
        raw_output = ""
        first_content = True

        for line in process.stdout:
            raw_output += line
            line = line.strip()
            if not line:
                continue

            # å°è¯• SSE æ ¼å¼
            if line.startswith("data: "):
                data = line[6:]
                if data == "[DONE]":
                    break
                try:
                    chunk = json.loads(data)
                    if "choices" in chunk and chunk["choices"]:
                        delta = chunk["choices"][0].get("delta", {})
                        content = delta.get("content", "")
                        if content:
                            if first_content and spinner:
                                spinner.stop()
                                first_content = False
                            print(content, end="", flush=True)
                            full_response += content
                except json.JSONDecodeError:
                    continue

        process.wait()

        # å¦‚æœæ²¡æœ‰ SSE æµæ•°æ®ï¼Œå°è¯•è§£æå®Œæ•´ JSON
        if not full_response and raw_output.strip():
            if spinner:
                spinner.stop()
            try:
                result = json.loads(raw_output.strip())
                if "choices" in result and result["choices"]:
                    content = result["choices"][0].get("message", {}).get("content", "")
                    if content:
                        print(content)
                        return content
            except json.JSONDecodeError:
                pass

        if full_response:
            print()  # æ¢è¡Œ
        return full_response if full_response else "[æ— å“åº”]"

    except Exception as e:
        if spinner:
            spinner.stop()
        return f"[æµå¼è¯·æ±‚é”™è¯¯]: {str(e)}"
    finally:
        if spinner and first_content:  # spinner è¿˜åœ¨è¿è¡Œ
            spinner.stop()


def chat_request_with_fallback_stream(messages, model, backend_config, debug=False):
    """æµå¼è¯·æ±‚ï¼Œå¤±è´¥æ—¶é™çº§"""
    response = chat_request_stream(messages, model, backend_config, debug=debug)

    if response.startswith("[") and model in FALLBACK_MODELS:
        fallback_model = FALLBACK_MODELS[model]
        print(f"\nâš ï¸  {model} è¯·æ±‚å¤±è´¥ï¼Œé™çº§åˆ° {fallback_model}...")
        response = chat_request_stream(messages, fallback_model, backend_config, debug=debug)

    return response


def auto_save_history(messages, model):
    """è‡ªåŠ¨ä¿å­˜ä¼šè¯å†å²åˆ° ~/.gchat/sessions/"""
    if not messages or len(messages) == 0:
        return  # æ²¡æœ‰å¯¹è¯å†…å®¹ï¼Œä¸ä¿å­˜

    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = os.path.join(get_sessions_dir(), f"gchat_history_{timestamp}.json")

    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                "model": model,
                "messages": messages,
                "timestamp": timestamp
            }, f, ensure_ascii=False, indent=2)
        print(colored(f"ğŸ’¾ ä¼šè¯å·²è‡ªåŠ¨ä¿å­˜åˆ°: {filename}", Color.GREEN))
    except Exception as e:
        print(colored(f"âš ï¸  è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}", Color.RED))

def load_latest_history():
    """åŠ è½½æœ€æ–°çš„ä¼šè¯å†å²"""
    import glob

    sessions_dir = get_sessions_dir()
    history_files = glob.glob(os.path.join(sessions_dir, "gchat_history_*.json"))
    if not history_files:
        return None, None, None

    # æŒ‰æ–‡ä»¶åæ’åºï¼ˆæ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ï¼Œè‡ªç„¶æ’åºå³å¯ï¼‰
    latest_file = sorted(history_files)[-1]

    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get("messages", []), data.get("model", "gemini-3-flash-preview"), latest_file
    except Exception as e:
        print(colored(f"âš ï¸  åŠ è½½ä¼šè¯å¤±è´¥: {e}", Color.RED))
        return None, None, None


def list_sessions():
    """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
    sessions_dir = get_sessions_dir()
    history_files = glob_module.glob(os.path.join(sessions_dir, "gchat_history_*.json"))

    if not history_files:
        print(colored("æ²¡æœ‰ä¿å­˜çš„ä¼šè¯", Color.YELLOW))
        return []

    sessions = []
    for f in sorted(history_files, reverse=True):
        try:
            with open(f, 'r', encoding='utf-8') as fp:
                data = json.load(fp)
                msg_count = len(data.get("messages", []))
                model = data.get("model", "unknown")
                timestamp = data.get("timestamp", "")
                # è·å–ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºé¢„è§ˆ
                preview = ""
                for msg in data.get("messages", []):
                    if msg.get("role") == "user":
                        content = msg.get("content", "")
                        if isinstance(content, str):
                            preview = content[:50] + "..." if len(content) > 50 else content
                        break
                sessions.append({
                    "file": f,
                    "timestamp": timestamp,
                    "model": model,
                    "msg_count": msg_count,
                    "preview": preview
                })
        except Exception:
            continue

    return sessions


def read_file_content(file_path):
    """è¯»å–æ–‡ä»¶å†…å®¹ç”¨äºAIåˆ†æ"""
    path = Path(file_path).expanduser()
    if not path.exists():
        return None, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"

    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡
    if is_image_file(path):
        return {"type": "image", "path": str(path)}, None

    # è¯»å–æ–‡æœ¬æ–‡ä»¶
    try:
        # é™åˆ¶æ–‡ä»¶å¤§å° (æœ€å¤§ 500KB)
        if path.stat().st_size > 500 * 1024:
            return None, f"æ–‡ä»¶è¿‡å¤§ (>{500}KB): {file_path}"

        with open(path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        return {"type": "text", "content": content, "path": str(path)}, None
    except Exception as e:
        return None, f"è¯»å–å¤±è´¥: {e}"


def write_to_file(file_path, content):
    """å°†å†…å®¹å†™å…¥æ–‡ä»¶"""
    path = Path(file_path).expanduser()
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True, str(path)
    except Exception as e:
        return False, str(e)


def execute_function(name, args):
    """æ‰§è¡Œå‡½æ•°è°ƒç”¨ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    if name == "get_weather":
        city = args.get("city", "æœªçŸ¥")
        # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
        return {"city": city, "temperature": "15Â°C", "condition": "æ™´", "humidity": "45%"}
    elif name == "web_search":
        query = args.get("query", "")
        return {"results": [f"å…³äº '{query}' çš„æœç´¢ç»“æœ...", "æ›´å¤šå†…å®¹è¯·è®¿é—®æœç´¢å¼•æ“"]}
    elif name == "calculate":
        expr = args.get("expression", "0")
        try:
            # å®‰å…¨çš„æ•°å­¦è®¡ç®—
            import math
            allowed = {"sqrt": math.sqrt, "sin": math.sin, "cos": math.cos, "tan": math.tan,
                      "log": math.log, "exp": math.exp, "abs": abs, "round": round, "pow": pow}
            result = eval(expr, {"__builtins__": {}}, allowed)
            return {"expression": expr, "result": result}
        except Exception as e:
            return {"error": str(e)}
    elif name == "run_bash":
        command = args.get("command", "")
        try:
            result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=30)
            return {"command": command, "stdout": result.stdout, "stderr": result.stderr, "returncode": result.returncode}
        except Exception as e:
            return {"error": str(e)}
    elif name == "write_file":
        path = args.get("path", "")
        content = args.get("content", "")
        try:
            with open(path, "w", encoding="utf-8") as f:
                f.write(content)
            return {"success": True, "path": path, "message": f"å·²å†™å…¥ {len(content)} å­—ç¬¦åˆ° {path}"}
        except Exception as e:
            return {"error": str(e)}
    elif name == "read_file":
        path = args.get("path", "")
        try:
            with open(path, "r", encoding="utf-8") as f:
                content = f.read()
            return {"success": True, "path": path, "content": content[:5000]}  # é™åˆ¶é•¿åº¦
        except Exception as e:
            return {"error": str(e)}
    else:
        return {"error": f"æœªçŸ¥å‡½æ•°: {name}"}


def interactive_mode(model, backend_name, continue_session=False):
    """äº¤äº’å¼å¤šè½®ä¼šè¯"""
    backend_config = BACKENDS[backend_name]
    model = resolve_model(model)
    messages = []
    loaded_file = None
    # é»˜è®¤å¯ç”¨æ–‡ä»¶è¯»å†™å·¥å…·
    enabled_tools = [BUILTIN_TOOLS["read"], BUILTIN_TOOLS["write"]]
    use_stream = True   # é»˜è®¤å¯ç”¨æµå¼è¾“å‡º

    # å¦‚æœæ˜¯ç»§ç»­ä¼šè¯æ¨¡å¼ï¼Œå°è¯•åŠ è½½æœ€è¿‘çš„å†å²
    if continue_session:
        loaded_messages, loaded_model, loaded_file = load_latest_history()
        if loaded_messages:
            messages = loaded_messages
            if loaded_model:
                model = loaded_model
            print(colored("â—‹", Color.DIM) + f" Loaded: {colored(loaded_file, Color.DIM)}")
            print(colored("â—‹", Color.DIM) + f" Messages: {colored(f'{len(messages)} ({len(messages)//2} turns)', Color.DIM)}")
            print()

    print_header()
    # çŠ¶æ€å±‚ - ç´§å‡‘å•è¡Œæ˜¾ç¤º
    session_status = 'continuing' if (continue_session and loaded_file) else 'new'
    status_line = (
        colored("  model:", Color.DIM) + colored(f" {model}", Color.CYAN) +
        colored("  session:", Color.DIM) + colored(f" {session_status}", Color.GREEN)
    )
    print(status_line)
    print()

    input_mode = 'normal'  # normal | box
    history = None
    # æ£€æŸ¥ç»ˆç«¯å¯ç”¨æ€§ - åŒæ—¶æ£€æŸ¥ stdin å’Œ stdout
    is_interactive = sys.stdin.isatty() or sys.stdout.isatty()
    if pt_prompt and FileHistory:
        try:
            history = FileHistory(get_input_history_path())
        except Exception:
            history = None

    def prompt_text() -> str:
        # Claude Code é£æ ¼è¾“å…¥æ¡†
        if input_mode == 'box':
            return colored("â€º ", Color.MAGENTA + Color.BOLD) + colored("[box] ", Color.DIM)
        return colored("â€º ", Color.MAGENTA + Color.BOLD)

    def read_user_message(force_box: bool = False, default_text: str = "") -> str | None:
        """è¯»å–ç”¨æˆ·è¾“å…¥ã€‚

        - normal: å•è¡Œ Enter å‘é€ï¼›å¦‚æœå†…å®¹å·²åŒ…å«æ¢è¡Œï¼ˆå¸¸è§äºç²˜è´´ï¼‰ï¼ŒEnter ç»§ç»­æ¢è¡Œï¼ŒCtrl+S å‘é€
        - box: å¤šè¡Œè¾“å…¥æ¡†ï¼›Enter æ¢è¡Œï¼ŒCtrl+S å‘é€ï¼ŒCtrl+G å–æ¶ˆ
        """
        use_box = force_box or (input_mode == 'box')

        if pt_prompt and KeyBindings:
            kb = KeyBindings()
            cancel_token = "__CANCEL__"

            @kb.add('c-g')
            def _(event):
                event.app.exit(result=cancel_token)

            @kb.add('c-c')
            def _(event):
                buf = event.current_buffer
                if buf.text:
                    buf.reset()
                    return
                event.app.exit(result=cancel_token)

            @kb.add('c-s')
            def _(event):
                event.current_buffer.validate_and_handle()

            @kb.add('enter')
            def _(event):
                buf = event.current_buffer
                text = buf.text

                if text.endswith('\\'):
                    buf.delete_before_cursor(count=1)
                    buf.insert_text('\n')
                    return

                if use_box:
                    buf.insert_text('\n')
                    return

                if '\n' in text:
                    buf.insert_text('\n')
                    return

                buf.validate_and_handle()

            prompt_obj = PTANSI(prompt_text()) if PTANSI else prompt_text()

            # å ä½æç¤ºæ–‡å­—
            placeholder_text = HTML('<style fg="ansibrightblack">Type message or /help for commands</style>') if HTML else None

            # åº•éƒ¨çŠ¶æ€æ 
            def get_toolbar():
                msg_count = len(messages)
                turns = msg_count // 2
                stream_status = "stream on" if use_stream else "stream off"
                return HTML(f'<style fg="ansibrightblack">  {model}  Â·  {turns} turns  Â·  {stream_status}</style>')

            toolbar_func = get_toolbar if HTML else None

            try:
                text = pt_prompt(
                    prompt_obj,
                    default=default_text,
                    multiline=True,
                    key_bindings=kb,
                    history=history,
                    wrap_lines=True,
                    placeholder=placeholder_text,
                    bottom_toolbar=toolbar_func,
                )
            except KeyboardInterrupt:
                return None
            if text == cancel_token:
                return None
            return sanitize_terminal_paste(text)

        prompt = readline_safe_prompt(prompt_text())
        cont_prompt = readline_safe_prompt(colored("...> ", Color.BOLD))

        # ç¡®ä¿æç¤ºç¬¦æ˜¾ç¤º
        sys.stdout.flush()

        if use_box:
            print(colored("è¾“å…¥æ¡†æ¨¡å¼ï¼šè¾“å…¥å¤šè¡Œï¼Œå•ç‹¬ä¸€è¡Œè¾“å…¥ . ç»“æŸï¼›ç©ºå†…å®¹å–æ¶ˆã€‚", Color.YELLOW))
            lines: list[str] = []
            while True:
                try:
                    l = input(cont_prompt)
                except KeyboardInterrupt:
                    return None
                if l == '.':
                    break
                lines.append(l)
            text = "\n".join(lines)
            text = sanitize_terminal_paste(text)
            return text if text.strip() else None

        try:
            line = input(prompt)
        except KeyboardInterrupt:
            return None
        lines = []
        while True:
            if line.endswith('\\'):
                lines.append(line[:-1])
                try:
                    line = input(cont_prompt)
                except KeyboardInterrupt:
                    return None
                continue
            lines.append(line)
            break
        return sanitize_terminal_paste("\n".join(lines))

    def maybe_confirm_box(text: str) -> str | None:
        show = (input_mode == 'box') or ('\n' in text) or (len(text) >= 400)
        if not show:
            return text

        while True:
            print_box("å†…å®¹", text)
            ans = input("å‘é€ï¼Ÿ[Enter]=å‘é€, e=ç¼–è¾‘, c=å–æ¶ˆ > ").strip().lower()
            if ans in {'', 'y', 'yes'}:
                return text
            if ans in {'c', 'cancel', 'n', 'no'}:
                return None
            if ans in {'e', 'edit'}:
                edited = read_user_message(force_box=True, default_text=text)
                if edited is None:
                    return None
                text = edited
                continue

    while True:
        try:
            user_input_raw = read_user_message()
            if user_input_raw is None:
                continue

            user_input = user_input_raw.strip()

            if user_input == '/paste':
                pasted = read_user_message(force_box=True)
                if pasted is None:
                    continue
                user_input = pasted.strip()


            if not user_input:
                continue

            # å¤„ç†å‘½ä»¤
            if user_input.startswith('/'):
                cmd_parts = user_input[1:].split(maxsplit=1)
                cmd = cmd_parts[0].lower()
                cmd_arg = cmd_parts[1] if len(cmd_parts) > 1 else None

                if cmd in ['quit', 'q', 'exit']:
                    auto_save_history(messages, model)
                    print(colored("  bye.", Color.DIM))
                    break
                elif cmd in ['help', 'h']:
                    print_help()
                elif cmd in ['clear', 'c']:
                    if messages:
                        msg_count = len(messages)
                        round_count = msg_count // 2
                        print(colored(f"ğŸ—‘ï¸  å·²æ¸…ç©º {msg_count} æ¡æ¶ˆæ¯ ({round_count} è½®å¯¹è¯)", Color.YELLOW))
                        print(colored("   ä¸Šä¸‹æ–‡å·²é‡ç½®ï¼Œå¼€å§‹æ–°çš„å¯¹è¯", Color.YELLOW))
                        messages = []
                    else:
                        print(colored("å¯¹è¯å†å²æœ¬æ¥å°±æ˜¯ç©ºçš„", Color.YELLOW))
                elif cmd == 'history':
                    if not messages:
                        print(colored("å¯¹è¯å†å²ä¸ºç©º", Color.YELLOW))
                    else:
                        for i, msg in enumerate(messages):
                            role = "You" if msg["role"] == "user" else "AI"
                            content = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
                            print(f"  [{i+1}] {role}: {content}")
                elif cmd == 'model':
                    if cmd_arg:
                        model = resolve_model(cmd_arg)
                        print(colored(f"æ¨¡å‹å·²åˆ‡æ¢åˆ°: {model}", Color.GREEN))
                    else:
                        print(f"å½“å‰æ¨¡å‹: {model}")
                        print(f"å¯ç”¨æ¨¡å‹: flash, pro, pro3")
                elif cmd == 'backend':
                    if cmd_arg and cmd_arg in BACKENDS:
                        backend_name = cmd_arg
                        backend_config = BACKENDS[backend_name]
                        print(colored(f"åç«¯å·²åˆ‡æ¢åˆ°: {backend_config['name']}", Color.GREEN))
                    else:
                        print(f"å½“å‰åç«¯: {backend_config['name']}")
                        print(f"å¯ç”¨åç«¯: {', '.join(BACKENDS.keys())}")
                elif cmd == 'status':
                    print(f"æ¨¡å‹: {model}")
                    print(f"åç«¯: {backend_config['name']}")
                    print(f"å¯¹è¯è½®æ•°: {len(messages) // 2}")
                    print(f"æµå¼è¾“å‡º: {'å¼€å¯' if use_stream else 'å…³é—­'}")
                    if enabled_tools:
                        print(f"å¯ç”¨å·¥å…·: {', '.join([t['name'] for t in enabled_tools])}")
                        if backend_config.get("supports_tools"):
                            print(colored("  ğŸ’¡ å½“å‰åç«¯æ”¯æŒ Function Calling", Color.GREEN))
                        else:
                            print(colored("  âš ï¸  å½“å‰åç«¯ä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œè¯·åˆ‡æ¢åˆ° google åç«¯", Color.YELLOW))
                    else:
                        print(f"å¯ç”¨å·¥å…·: æ— ")
                elif cmd == 'sessions':
                    # åˆ—å‡ºæ‰€æœ‰ä¼šè¯
                    sessions = list_sessions()
                    if sessions:
                        print(colored("ä¿å­˜çš„ä¼šè¯:", Color.GREEN))
                        for i, s in enumerate(sessions[:10]):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                            ts = s["timestamp"]
                            if ts:
                                ts = f"{ts[:4]}-{ts[4:6]}-{ts[6:8]} {ts[9:11]}:{ts[11:13]}"
                            print(f"  [{i+1}] {ts} | {s['model']} | {s['msg_count']}æ¡ | {s['preview']}")
                        if len(sessions) > 10:
                            print(colored(f"  ... è¿˜æœ‰ {len(sessions) - 10} ä¸ªä¼šè¯", Color.DIM))
                        print(colored("\nä½¿ç”¨ /load <ç¼–å·> åŠ è½½ä¼šè¯", Color.YELLOW))
                elif cmd == 'read':
                    # è¯»å–æ–‡ä»¶
                    if not cmd_arg:
                        print(colored("ç”¨æ³•: /read <æ–‡ä»¶è·¯å¾„>", Color.YELLOW))
                        continue
                    file_result, error = read_file_content(cmd_arg)
                    if error:
                        print(colored(error, Color.RED))
                        continue
                    if file_result["type"] == "image":
                        # å›¾ç‰‡æ–‡ä»¶ï¼Œè½¬åˆ°å›¾ç‰‡å¤„ç†
                        print(colored(f"ğŸ“· æ£€æµ‹åˆ°å›¾ç‰‡: {file_result['path']}", Color.CYAN))
                        user_message = {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "è¯·æè¿°è¿™å¼ å›¾ç‰‡ã€‚"},
                                {"type": "image_file", "path": file_result["path"]}
                            ],
                        }
                    else:
                        # æ–‡æœ¬æ–‡ä»¶
                        content = file_result["content"]
                        file_path = file_result["path"]
                        line_count = content.count('\n') + 1
                        print(colored(f"ğŸ“„ å·²è¯»å–: {file_path} ({line_count} è¡Œ)", Color.CYAN))
                        user_message = {
                            "role": "user",
                            "content": f"è¯·åˆ†æä»¥ä¸‹æ–‡ä»¶å†…å®¹:\n\næ–‡ä»¶: {file_path}\n\n```\n{content}\n```"
                        }
                    messages.append(user_message)
                    print()  # AI response follows
                    if use_stream:
                        response = chat_request_with_fallback_stream(messages, model, backend_config)
                    else:
                        response = chat_request_with_fallback(messages, model, backend_config)
                        print(response)
                    print()
                    messages.append({"role": "assistant", "content": response})
                elif cmd == 'write':
                    # å†™å…¥æ–‡ä»¶
                    if not cmd_arg:
                        print(colored("ç”¨æ³•: /write <æ–‡ä»¶è·¯å¾„>", Color.YELLOW))
                        continue
                    if not messages:
                        print(colored("æ²¡æœ‰å¯ä¿å­˜çš„å†…å®¹", Color.YELLOW))
                        continue
                    # è·å–æœ€åä¸€æ¡AIå›å¤
                    last_response = None
                    for msg in reversed(messages):
                        if msg.get("role") == "assistant":
                            last_response = msg.get("content", "")
                            break
                    if not last_response:
                        print(colored("æ²¡æœ‰AIå›å¤å¯ä¿å­˜", Color.YELLOW))
                        continue
                    success, result = write_to_file(cmd_arg, last_response)
                    if success:
                        print(colored(f"âœ… å·²ä¿å­˜åˆ°: {result}", Color.GREEN))
                    else:
                        print(colored(f"âŒ ä¿å­˜å¤±è´¥: {result}", Color.RED))
                elif cmd == 'stream':
                    # åˆ‡æ¢æµå¼è¾“å‡º
                    use_stream = not use_stream
                    print(colored(f"æµå¼è¾“å‡º: {'å¼€å¯' if use_stream else 'å…³é—­'}", Color.GREEN))
                elif cmd == 'tools':
                    if not cmd_arg:
                        # åˆ—å‡ºå½“å‰å¯ç”¨çš„å·¥å…·
                        if enabled_tools:
                            print(colored("å½“å‰å¯ç”¨çš„å·¥å…·:", Color.GREEN))
                            for t in enabled_tools:
                                print(f"  ğŸ”§ {t['name']}: {t['description']}")
                        else:
                            print(colored("å½“å‰æ²¡æœ‰å¯ç”¨ä»»ä½•å·¥å…·", Color.YELLOW))
                            print("ä½¿ç”¨ /tools add <name> æ·»åŠ å·¥å…·ï¼Œå¯ç”¨: " + ", ".join(BUILTIN_TOOLS.keys()))
                    else:
                        parts = cmd_arg.split(maxsplit=1)
                        subcmd = parts[0].lower()
                        subarg = parts[1] if len(parts) > 1 else None

                        if subcmd == 'list':
                            print(colored("å¯ç”¨å·¥å…·:", Color.GREEN))
                            for name, tool in BUILTIN_TOOLS.items():
                                status = "âœ…" if any(t['name'] == tool['name'] for t in enabled_tools) else "  "
                                print(f"  {status} {name}: {tool['description']}")
                        elif subcmd == 'add':
                            if subarg and subarg in BUILTIN_TOOLS:
                                tool = BUILTIN_TOOLS[subarg]
                                if not any(t['name'] == tool['name'] for t in enabled_tools):
                                    enabled_tools.append(tool)
                                    print(colored(f"âœ… å·²æ·»åŠ å·¥å…·: {tool['name']}", Color.GREEN))
                                    print(colored("   ğŸ’¡ å¯ç”¨å·¥å…·åä¼šè‡ªåŠ¨ä½¿ç”¨å®˜æ–¹APIè¿›è¡ŒFunction Calling", Color.YELLOW))
                                else:
                                    print(colored(f"å·¥å…· {subarg} å·²ç»å¯ç”¨", Color.YELLOW))
                            else:
                                print(f"æœªçŸ¥å·¥å…·: {subarg}")
                                print("å¯ç”¨å·¥å…·: " + ", ".join(BUILTIN_TOOLS.keys()))
                        elif subcmd == 'remove':
                            if subarg:
                                tool = BUILTIN_TOOLS.get(subarg)
                                if tool:
                                    enabled_tools = [t for t in enabled_tools if t['name'] != tool['name']]
                                    print(colored(f"âŒ å·²ç§»é™¤å·¥å…·: {tool['name']}", Color.YELLOW))
                                else:
                                    print(f"æœªçŸ¥å·¥å…·: {subarg}")
                            else:
                                print("ç”¨æ³•: /tools remove <name>")
                        elif subcmd == 'clear':
                            enabled_tools = []
                            print(colored("å·²æ¸…ç©ºæ‰€æœ‰å·¥å…·", Color.YELLOW))
                        else:
                            print(f"æœªçŸ¥å­å‘½ä»¤: {subcmd}")
                            print("ç”¨æ³•: /tools [list|add|remove|clear]")
                elif cmd == 'call':
                    # å¼ºåˆ¶ä½¿ç”¨å®˜æ–¹APIè¿›è¡ŒFunction Calling
                    if not cmd_arg:
                        print("ç”¨æ³•: /call <æç¤ºè¯>")
                        continue

                    if not enabled_tools:
                        print(colored("âš ï¸  æ²¡æœ‰å¯ç”¨ä»»ä½•å·¥å…·ï¼Œè¯·å…ˆä½¿ç”¨ /tools add <name> æ·»åŠ å·¥å…·", Color.YELLOW))
                        continue

                    print(colored(f"ğŸ”§ ä½¿ç”¨å®˜æ–¹APIè¿›è¡ŒFunction Calling...", Color.CYAN))
                    messages.append({"role": "user", "content": cmd_arg})

                    result, error = official_api_request(messages, model, enabled_tools)
                    if error:
                        print(colored(error, Color.RED))
                        messages.pop()  # ç§»é™¤å¤±è´¥çš„æ¶ˆæ¯
                        continue

                    if result["type"] == "function_call":
                        fc_name = result["name"]
                        fc_args = result["args"]
                        print(colored(f"ğŸ“ å‡½æ•°è°ƒç”¨: {fc_name}({json.dumps(fc_args, ensure_ascii=False)})", Color.YELLOW))

                        # æ‰§è¡Œå‡½æ•°
                        fc_result = execute_function(fc_name, fc_args)
                        print(colored(f"ğŸ“¤ å‡½æ•°ç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}", Color.GREEN))

                        # è®°å½•åˆ°å†å²
                        messages.append({"role": "assistant", "content": f"[è°ƒç”¨å‡½æ•° {fc_name}]\nå‚æ•°: {json.dumps(fc_args, ensure_ascii=False)}\nç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}"})
                    else:
                        print()  # AI response follows
                        print(result["content"])
                        messages.append({"role": "assistant", "content": result["content"]})
                    print()
                elif cmd == 'save':
                    if cmd_arg:
                        try:
                            with open(cmd_arg, 'w', encoding='utf-8') as f:
                                json.dump({"model": model, "messages": messages}, f, ensure_ascii=False, indent=2)
                            print(colored(f"å¯¹è¯å·²ä¿å­˜åˆ°: {cmd_arg}", Color.GREEN))
                        except Exception as e:
                            print(colored(f"ä¿å­˜å¤±è´¥: {e}", Color.RED))
                    else:
                        print("ç”¨æ³•: /save <æ–‡ä»¶å>")
                elif cmd == 'load':
                    if cmd_arg:
                        try:
                            with open(cmd_arg, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                messages = data.get("messages", [])
                                model = data.get("model", model)
                            print(colored(f"å¯¹è¯å·²åŠ è½½ï¼Œå…± {len(messages)} æ¡æ¶ˆæ¯", Color.GREEN))
                        except Exception as e:
                            print(colored(f"åŠ è½½å¤±è´¥: {e}", Color.RED))
                    else:
                        print("ç”¨æ³•: /load <æ–‡ä»¶å>")
                elif cmd == 'mode':
                    if not cmd_arg:
                        input_mode = 'box' if input_mode == 'normal' else 'normal'
                    else:
                        arg = cmd_arg.strip().lower()
                        if arg in {'normal', 'n'}:
                            input_mode = 'normal'
                        elif arg in {'box', 'b'}:
                            input_mode = 'box'
                        else:
                            print(colored("ç”¨æ³•: /mode [normal|box]", Color.YELLOW))
                            continue
                    print(colored(f"è¾“å…¥æ¨¡å¼å·²åˆ‡æ¢åˆ°: {input_mode}", Color.GREEN))
                elif cmd in {'img', 'image'}:
                    try:
                        parts = shlex.split(user_input, posix=True)
                    except ValueError as e:
                        print(colored(f"å‚æ•°è§£æå¤±è´¥: {e}", Color.RED))
                        continue

                    args = parts[1:]
                    if not args:
                        print(colored("ç”¨æ³•: /img <å›¾ç‰‡è·¯å¾„...> [æè¿°æ–‡æœ¬]", Color.YELLOW))
                        continue

                    image_paths: list[Path] = []
                    text_parts: list[str] = []
                    for tok in args:
                        p = Path(tok).expanduser()
                        if is_image_file(p):
                            image_paths.append(p)
                        else:
                            text_parts.append(tok)

                    if not image_paths:
                        print(colored("æœªæ£€æµ‹åˆ°æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒ png/jpg/jpeg/webp/gif ç­‰ï¼‰", Color.YELLOW))
                        continue

                    user_text = " ".join(text_parts).strip() or "è¯·æè¿°è¿™å¼ å›¾ç‰‡ã€‚"
                    confirmed_text = maybe_confirm_box(user_text)
                    if confirmed_text is None:
                        continue

                    user_message = {
                        "role": "user",
                        "content": [{"type": "text", "text": confirmed_text}] + [
                            {"type": "image_file", "path": str(p)} for p in image_paths
                        ],
                    }
                    messages.append(user_message)

                    print()  # AI response follows
                    response = chat_request_with_fallback(messages, model, backend_config)
                    print(response)
                    print()
                    messages.append({"role": "assistant", "content": response})
                else:
                    print(colored(f"æœªçŸ¥å‘½ä»¤: /{cmd}ï¼Œè¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©", Color.RED))
                continue

            # å›¾ç‰‡ï¼šæ”¯æŒç›´æ¥æ‹–æ‹½å›¾ç‰‡è·¯å¾„åˆ°è¾“å…¥æ¡†
            cleaned_text, image_paths = extract_local_image_paths(user_input)
            if image_paths:
                user_text = cleaned_text or "è¯·æè¿°è¿™å¼ å›¾ç‰‡ã€‚"
                confirmed_text = maybe_confirm_box(user_text)
                if confirmed_text is None:
                    continue
                messages.append({
                    "role": "user",
                    "content": [{"type": "text", "text": confirmed_text}] + [
                        {"type": "image_file", "path": str(p)} for p in image_paths
                    ],
                })
            else:
                confirmed_text = maybe_confirm_box(user_input)
                if confirmed_text is None:
                    continue
                messages.append({"role": "user", "content": confirmed_text})

            # å‘é€è¯·æ±‚ - æ··åˆè·¯ç”±é€»è¾‘
            print()  # AI response follows

            if enabled_tools and backend_config.get("supports_tools"):
                # æœ‰å·¥å…·ä¸”åç«¯æ”¯æŒæ—¶ï¼Œä½¿ç”¨å·¥å…·è°ƒç”¨
                if backend_name == "google":
                    # google åç«¯ä½¿ç”¨ OpenAI æ ¼å¼
                    result, error = openai_tools_request(messages, model, enabled_tools, backend_config)
                else:
                    # official åç«¯ä½¿ç”¨ Gemini åŸç”Ÿæ ¼å¼
                    result, error = official_api_request(messages, model, enabled_tools)

                if error:
                    print(colored(error, Color.RED))
                    messages.pop()  # ç§»é™¤å¤±è´¥çš„æ¶ˆæ¯
                    continue

                if result["type"] == "function_call":
                    fc_name = result["name"]
                    fc_args = result["args"]
                    print(colored(f"ğŸ“ å‡½æ•°è°ƒç”¨: {fc_name}({json.dumps(fc_args, ensure_ascii=False)})", Color.YELLOW))

                    # æ‰§è¡Œå‡½æ•°
                    fc_result = execute_function(fc_name, fc_args)
                    print(colored(f"ğŸ“¤ å‡½æ•°ç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}", Color.GREEN))

                    # è®°å½•åˆ°å†å²
                    response = f"[è°ƒç”¨å‡½æ•° {fc_name}]\nå‚æ•°: {json.dumps(fc_args, ensure_ascii=False)}\nç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}"
                else:
                    response = result["content"]
                    print(response)
            else:
                # æ— å·¥å…·æˆ–åç«¯ä¸æ”¯æŒæ—¶ä½¿ç”¨æ™®é€šè¯·æ±‚
                if use_stream:
                    response = chat_request_with_fallback_stream(messages, model, backend_config)
                else:
                    response = chat_request_with_fallback(messages, model, backend_config)
                    print(response)

            print()

            # æ·»åŠ AIå›å¤åˆ°å†å²
            messages.append({"role": "assistant", "content": response})

        except KeyboardInterrupt:
            # å®æ—¶ä¸­æ–­ï¼šä¿å­˜ä¸Šä¸‹æ–‡
            print("\n" + colored("ğŸ’¾ å·²ä¿å­˜ä¸Šä¸‹æ–‡ï¼ŒæŒ‰ Enter ç»§ç»­æˆ– /q é€€å‡º", Color.YELLOW))
            auto_save_history(messages, model)
        except EOFError:
            print()
            auto_save_history(messages, model)
            print(colored("  bye.", Color.DIM))
            break

def single_prompt(prompt, model, backend_name, output_json=False, use_stream=False):
    """å•æ¬¡æé—®æ¨¡å¼"""
    backend_config = BACKENDS[backend_name]
    model = resolve_model(model)
    messages = [{"role": "user", "content": prompt}]

    if use_stream and not output_json:
        response = chat_request_with_fallback_stream(messages, model, backend_config)
    else:
        response = chat_request_with_fallback(messages, model, backend_config)

    if output_json:
        result = {
            "model": model,
            "backend": backend_name,
            "prompt": prompt,
            "response": response,
            "success": not response.startswith("[")
        }
        print(json.dumps(result, ensure_ascii=False, indent=2))
    elif not use_stream:
        print(response)

def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    print("å¯ç”¨æ¨¡å‹:")
    print("  flash   -> gemini-3-flash-preview (æœ€æ–° 3.0 Flash) â­ æ¨è")
    print("  flash3  -> gemini-3-flash-preview (åŒä¸Š)")
    print("  flash2  -> gemini-2.5-flash (æ—§ç‰ˆ Flash)")
    print("  pro     -> gemini-2.5-pro (Pro)")
    print("  pro3    -> gemini-3.0-pro (3.0 Pro)")
    print()
    print("å¯ç”¨åç«¯:")
    for name, config in BACKENDS.items():
        tools_support = "âœ… æ”¯æŒFunction Calling" if config.get("supports_tools") else ""
        print(f"  {name:8} -> {config['name']} {tools_support}")
    print()
    print("å¯ç”¨å·¥å…· (ç”¨äºFunction Calling):")
    for name, tool in BUILTIN_TOOLS.items():
        print(f"  {name:12} -> {tool['description']}")

def main():
    parser = argparse.ArgumentParser(
        description="Gemini Chat CLI - å¤šè½®ä¼šè¯å‘½ä»¤è¡Œå·¥å…· (Claude Code çš„è½»é‡å¤šæ¨¡å‹ç½‘å…³)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  gchat                    å¼€å¯æ–°å¯¹è¯ (æµå¼è¾“å‡º)
  gchat -c                 ç»§ç»­ä¸Šæ¬¡å¯¹è¯
  gchat -m pro             ä½¿ç”¨ pro æ¨¡å‹
  gchat -p "è§£é‡Šé‡å­è®¡ç®—"   å•æ¬¡æé—®
  gchat -p "é—®é¢˜" --json   JSON æ ¼å¼è¾“å‡º (è„šæœ¬é›†æˆ)
  gchat --backend openai   ä½¿ç”¨ OpenAI åç«¯

äº¤äº’å‘½ä»¤:
  /read <file>   è¯»å–æ–‡ä»¶è®© AI åˆ†æ
  /write <file>  ä¿å­˜ AI å›å¤åˆ°æ–‡ä»¶
  /sessions      åˆ—å‡ºæ‰€æœ‰ä¼šè¯
  /stream        åˆ‡æ¢æµå¼è¾“å‡º
  /help          æŸ¥çœ‹æ›´å¤šå‘½ä»¤
        """
    )

    parser.add_argument('-m', '--model', default='pro3',
                        help='æ¨¡å‹åç§° (pro3/flash3/pro/flashï¼Œé»˜è®¤: pro3)')
    parser.add_argument('-p', '--prompt',
                        help='å•æ¬¡æé—®ï¼ˆä¸è¿›å…¥äº¤äº’æ¨¡å¼ï¼‰')
    parser.add_argument('-c', '--continue', dest='continue_session', action='store_true',
                        help='ç»§ç»­ä¸Šæ¬¡ä¼šè¯ï¼ˆè‡ªåŠ¨åŠ è½½æœ€è¿‘çš„å†å²è®°å½•ï¼‰')
    parser.add_argument('-b', '--backend', default='google',
                        choices=BACKENDS.keys(),
                        help='åç«¯é€‰æ‹© (é»˜è®¤: google)')
    parser.add_argument('--json', dest='output_json', action='store_true',
                        help='è¾“å‡º JSON æ ¼å¼ï¼ˆç”¨äºè„šæœ¬é›†æˆï¼‰')
    parser.add_argument('--no-stream', dest='no_stream', action='store_true',
                        help='ç¦ç”¨æµå¼è¾“å‡º')
    parser.add_argument('--list-models', action='store_true',
                        help='åˆ—å‡ºå¯ç”¨æ¨¡å‹å’Œåç«¯')

    args = parser.parse_args()

    if args.list_models:
        list_models()
        return

    if args.prompt:
        single_prompt(args.prompt, args.model, args.backend,
                     output_json=args.output_json,
                     use_stream=not args.no_stream)
    else:
        interactive_mode(args.model, args.backend, continue_session=args.continue_session)

if __name__ == "__main__":
    main()
