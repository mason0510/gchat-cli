#!/usr/bin/env python3
"""
Gemini Chat CLI - å¤šè½®ä¼šè¯å‘½ä»¤è¡Œå·¥å…·
æ”¯æŒå¤šç§åç«¯ï¼šæœ¬åœ°Gemini Reverse APIã€NexusAIç­‰

ç”¨æ³•:
    gchat                    # äº¤äº’å¼å¤šè½®ä¼šè¯ï¼ˆé»˜è®¤ gemini-3-pro-previewï¼‰
    gflashchat               # ä½¿ç”¨ gemini-3-flash-preview
    gchat -m flash3          # ä½¿ç”¨ flash3 æ¨¡å‹
    gchat -p "ä½ å¥½"          # å•æ¬¡æé—®
    gchat --backend nexus    # ä½¿ç”¨NexusAIåç«¯
    gchat --list-models      # åˆ—å‡ºå¯ç”¨æ¨¡å‹
"""

import argparse
import json
import os
import sys
import subprocess
import readline  # æ”¯æŒå†å²è®°å½•å’Œè¡Œç¼–è¾‘
import base64
import mimetypes
import re
import shlex
import shutil
from pathlib import Path

from wcwidth import wcswidth, wcwidth


_CTRL_CHARS_RE = re.compile(r"[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]")


def sanitize_terminal_paste(text: str) -> str:
    """æ¸…ç†ç»ˆç«¯ç²˜è´´å¯èƒ½å¸¦æ¥çš„æ§åˆ¶å­—ç¬¦/è½¬ä¹‰åºåˆ—ã€‚

    ç›®çš„ï¼šé¿å…æŠŠä¸å¯è§æ§åˆ¶å­—ç¬¦å¸¦è¿› prompt / API è¯·æ±‚ï¼Œæˆ–è§¦å‘å¿«æ·é”®è¡Œä¸ºã€‚
    """
    if not text:
        return text

    # ç»Ÿä¸€æ¢è¡Œ
    text = text.replace("\r\n", "\n").replace("\r", "\n")

    # å¸¸è§çš„ bracketed paste åŒ…è£¹
    text = text.replace("\x1b[200~", "").replace("\x1b[201~", "")

    # ç§»é™¤ä¸å¯è§æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™æ¢è¡Œ/åˆ¶è¡¨ç¬¦ï¼‰
    return _CTRL_CHARS_RE.sub("", text)

try:
    from prompt_toolkit import prompt as pt_prompt
    from prompt_toolkit.formatted_text import ANSI as PTANSI
    from prompt_toolkit.history import FileHistory
    from prompt_toolkit.key_binding import KeyBindings
except Exception:
    pt_prompt = None
    PTANSI = None
    FileHistory = None
    KeyBindings = None

# åç«¯é…ç½®
BACKENDS = {
    "google": {
        "url": "https://google-api.aihang365.com/v1/chat/completions",
        "name": "Google API (å†…éƒ¨æœåŠ¡ï¼Œæ”¯æŒFunction Calling)",
        "supports_tools": True,
    },
    "local": {
        "url": "http://82.29.54.80:8100/v1/chat/completions",
        "name": "Gemini Reverse API (æœ¬åœ°)",
        "supports_tools": False,
    },
    "nexus": {
        "url": "https://nexusai.aihang365.com/v1/chat/completions",
        "key": "GeminiReverseTest2025abcdefghijklmnopqrstuvwx",
        "name": "NexusAI",
        "supports_tools": False,
    },
    "official": {
        "url": "https://gemini-official.aihang365.com/v1beta/models/{model}:generateContent",
        "key": os.environ.get("GEMINI_API_KEY", ""),
        "name": "Google Official API (via US Proxy)",
        "supports_tools": True,
        "default_model": "gemini-2.5-flash-lite",  # æœ‰å…è´¹é¢åº¦ä¸”æ”¯æŒtools
    },
}

# å®˜æ–¹APIæ¨¡å‹æ˜ å°„ (é€†å‘æ¨¡å‹å -> å®˜æ–¹æ¨¡å‹å)
OFFICIAL_MODEL_MAP = {
    "gemini-3-flash-preview": "gemini-2.5-flash-lite",
    "gemini-2.5-flash": "gemini-2.5-flash-lite",
    "gemini-2.5-pro": "gemini-2.5-flash-lite",  # proæ²¡å…è´¹é¢åº¦ï¼Œé™çº§åˆ°flash-lite
    "gemini-3.0-pro": "gemini-2.5-flash-lite",
}

# æ¨¡å‹åˆ«å
MODEL_ALIASES = {
    "pro3": "gemini-3-pro-preview",  # â­ gchat é»˜è®¤
    "flash3": "gemini-3-flash-preview",  # gflashchat é»˜è®¤
    "flash": "gemini-3-flash-preview",
    "flash2": "gemini-2.5-flash",  # æ—§ç‰ˆ Flash
    "pro": "gemini-2.5-pro",
    "3": "gemini-3.0-pro",
}

# æ¨¡å‹é™çº§æ˜ å°„ (gemini-3 å¤±è´¥æ—¶é™çº§åˆ° gemini-2.5)
FALLBACK_MODELS = {
    "gemini-3-pro-preview": "gemini-2.5-pro",
    "gemini-3-flash-preview": "gemini-2.5-flash",
}

# é¢„å®šä¹‰çš„å¸¸ç”¨å·¥å…·
BUILTIN_TOOLS = {
    "weather": {
        "name": "get_weather",
        "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "åŸå¸‚åç§°ï¼Œå¦‚'åŒ—äº¬'ã€'ä¸Šæµ·'"}
            },
            "required": ["city"]
        }
    },
    "search": {
        "name": "web_search",
        "description": "æœç´¢ç½‘é¡µè·å–ä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"}
            },
            "required": ["query"]
        }
    },
    "calculator": {
        "name": "calculate",
        "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—",
        "parameters": {
            "type": "object",
            "properties": {
                "expression": {"type": "string", "description": "æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚'2+2'ã€'sqrt(16)'"}
            },
            "required": ["expression"]
        }
    },
    "bash": {
        "name": "run_bash",
        "description": "æ‰§è¡Œbashå‘½ä»¤",
        "parameters": {
            "type": "object",
            "properties": {
                "command": {"type": "string", "description": "è¦æ‰§è¡Œçš„bashå‘½ä»¤"}
            },
            "required": ["command"]
        }
    },
}

# é¢œè‰²è¾“å‡º
class Color:
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    DIM = '\033[2m'
    BOLD = '\033[1m'
    END = '\033[0m'

def colored(text, color):
    """è¿”å›å¸¦é¢œè‰²çš„æ–‡æœ¬"""
    if not sys.stdout.isatty():
        return text
    return f"{color}{text}{Color.END}"


ANSI_ESCAPE_RE = re.compile(r"\x1b\[[0-9;]*m")


def readline_safe_prompt(prompt: str) -> str:
    """è®©å¸¦ ANSI é¢œè‰²çš„ prompt åœ¨ readline ä¸‹ä¸ç ´åæ¢è¡Œ/å…‰æ ‡å®šä½ã€‚

    Python çš„ readline ä¼šæŠŠ ANSI æ§åˆ¶åºåˆ—ä¹Ÿè®¡å…¥é•¿åº¦ï¼Œå¯¼è‡´é•¿æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œæ—¶å…‰æ ‡é”™ä½ã€‚
    ç”¨ \001/\002 åŒ…è£¹ä¸å¯è§å­—ç¬¦ç‰‡æ®µå¯ä¿®å¤è¯¥é—®é¢˜ã€‚
    """
    if not sys.stdin.isatty():
        return prompt

    try:
        # è‹¥ readline ä¸å¯ç”¨ï¼Œç›´æ¥è¿”å›
        import readline as _  # noqa: F401
    except Exception:
        return prompt

    def _wrap(match: re.Match[str]) -> str:
        return f"\001{match.group(0)}\002"

    return ANSI_ESCAPE_RE.sub(_wrap, prompt)


def get_input_history_path() -> str:
    home = os.path.expanduser('~')
    return os.path.join(home, '.gchat_input_history')


def print_box(title: str, content: str) -> None:
    width = shutil.get_terminal_size((100, 20)).columns
    width = max(60, min(width, 140))

    label = f"[{title}]"
    top = f"â”Œ{label}{'â”€' * max(1, width - 2 - len(label))}â”"
    bottom = f"â””{'â”€' * (width - 2)}â”˜"
    print(colored(top, Color.CYAN))

    def _wrap_display(raw: str, max_w: int) -> list[str]:
        if raw == "":
            return [""]

        out: list[str] = []
        buf: list[str] = []
        cur_w = 0
        for ch in raw.replace('\t', '    '):
            ch_w = wcwidth(ch)
            if ch_w < 0:
                ch_w = 0
            if cur_w + ch_w > max_w and buf:
                out.append(''.join(buf))
                buf = [ch]
                cur_w = ch_w
                continue
            buf.append(ch)
            cur_w += ch_w
        out.append(''.join(buf))
        return out

    inner_w = width - 4
    lines = content.splitlines() or [""]
    for raw in lines:
        for wline in _wrap_display(raw, inner_w):
            line_w = wcswidth(wline)
            if line_w < 0:
                line_w = len(wline)
            pad = " " * max(0, inner_w - line_w)
            print(colored("â”‚ ", Color.CYAN) + wline + pad + colored(" â”‚", Color.CYAN))

    print(colored(bottom, Color.CYAN))


def is_image_file(path: Path) -> bool:
    if not path.is_file():
        return False

    suffix = path.suffix.lower().lstrip('.')
    return suffix in {
        'png', 'jpg', 'jpeg', 'gif', 'webp', 'bmp', 'tiff', 'tif', 'heic'
    }


def encode_image_to_data_url(path: Path) -> str:
    mime, _ = mimetypes.guess_type(str(path))
    if not mime:
        # å°½é‡ç»™ä¸€ä¸ªåˆç†é»˜è®¤
        mime = f"image/{path.suffix.lower().lstrip('.')}" if path.suffix else "application/octet-stream"

    data = path.read_bytes()
    b64 = base64.b64encode(data).decode('ascii')
    return f"data:{mime};base64,{b64}"


def extract_local_image_paths(text: str) -> tuple[str, list[Path]]:
    """ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æœ¬åœ°å›¾ç‰‡è·¯å¾„ï¼ˆç”¨äºæ‹–æ‹½æ–‡ä»¶åˆ°ç»ˆç«¯åœºæ™¯ï¼‰ã€‚

    - ä»…å½“ token æŒ‡å‘çœŸå®å­˜åœ¨çš„æ–‡ä»¶ä¸”æ‰©å±•åæ˜¯å›¾ç‰‡æ—¶æ‰è®¤å®šä¸ºå›¾ç‰‡ã€‚
    - è¿”å›ï¼šç§»é™¤å›¾ç‰‡è·¯å¾„åçš„æ–‡æœ¬ + å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    """
    # ä»…å¯¹å•è¡Œè¾“å…¥åšè‡ªåŠ¨è¯†åˆ«ï¼Œé¿å…ç ´åç”¨æˆ·å¤šè¡Œæ–‡æœ¬æ ¼å¼
    if '\n' in text:
        return text, []

    try:
        tokens = shlex.split(text, posix=True)
    except ValueError:
        # å¼•å·ä¸é…å¯¹ç­‰æƒ…å†µï¼šä¿å®ˆå¤„ç†ï¼Œä¸è‡ªåŠ¨æå–
        return text, []

    image_paths: list[Path] = []
    remaining: list[str] = []
    for tok in tokens:
        p = Path(tok).expanduser()
        if is_image_file(p):
            image_paths.append(p)
        else:
            remaining.append(tok)

    cleaned_text = ' '.join(remaining).strip()
    return cleaned_text, image_paths


def normalize_messages_for_api(messages: list[dict]) -> list[dict]:
    """æŠŠæœ¬åœ° message ç»“æ„è½¬æ¢ä¸º OpenAI å…¼å®¹ payloadã€‚

    æ”¯æŒ content ä¸ºï¼š
    - str
    - list[{type:'text', text:'...'} | {type:'image_file', path:'...'}]
    """
    out: list[dict] = []
    for msg in messages:
        content = msg.get('content')
        if isinstance(content, list):
            parts: list[dict] = []
            for part in content:
                if part.get('type') == 'text':
                    text = part.get('text', '')
                    if text:
                        parts.append({"type": "text", "text": text})
                elif part.get('type') == 'image_file':
                    path_str = part.get('path')
                    if not path_str:
                        continue
                    p = Path(path_str).expanduser()
                    if not is_image_file(p):
                        continue
                    parts.append({
                        "type": "image_url",
                        "image_url": {"url": encode_image_to_data_url(p)},
                    })
                elif part.get('type') == 'image_url':
                    # å…¼å®¹å·²æ˜¯ OpenAI æ ¼å¼çš„å†å²è®°å½•
                    image_url = part.get('image_url')
                    if isinstance(image_url, dict) and image_url.get('url'):
                        parts.append({"type": "image_url", "image_url": {"url": image_url["url"]}})
                else:
                    # æœªçŸ¥ part ç±»å‹ï¼šå¿½ç•¥
                    continue

            # å¦‚æœ parts ä¸ºç©ºï¼Œè‡³å°‘ç»™ä¸€ä¸ªç©ºæ–‡æœ¬ï¼Œé¿å…éƒ¨åˆ†åç«¯æŠ¥é”™
            if not parts:
                parts = [{"type": "text", "text": ""}]

            out.append({"role": msg.get('role'), "content": parts})
        else:
            out.append({"role": msg.get('role'), "content": content})

    return out

def print_header():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯ - ç°ä»£æç®€é£æ ¼"""
    # 1. å“ç‰Œå±‚ (Brand & Version)
    print(colored("âœ¦ NexusAI CLI", Color.BOLD + Color.CYAN) + colored(" v4.0", Color.DIM))
    print()

    # 2. çŠ¶æ€å±‚ (Status Context) - ç”±è°ƒç”¨æ–¹åŠ¨æ€å¡«å……
    # print(colored("â—‹", Color.DIM) + " Status: " + colored("Ready to chat", Color.GREEN))
    # print(colored("â—‹", Color.DIM) + " Mode:   Default" + colored(" (Multi-line: /paste)", Color.DIM))
    # print(colored("â—‹", Color.DIM) + " Back:   Google API" + colored(" (Functional)", Color.DIM))
    # print()

    # 3. å¼•å¯¼å±‚ (Hints)
    print(colored("Type", Color.DIM) + " /help " + colored("for commands or", Color.DIM) + " /quit " + colored("to exit.", Color.DIM))

    # åˆ†éš”çº¿
    print(colored("â€”", Color.DIM))

def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    help_text = """
å¯ç”¨å‘½ä»¤:
  /help, /h      æ˜¾ç¤ºå¸®åŠ©
  /quit, /q      é€€å‡ºç¨‹åºï¼ˆè‡ªåŠ¨ä¿å­˜ä¼šè¯å†å²ï¼‰
  /clear, /c     æ¸…ç©ºå¯¹è¯å†å²
  /history       æ˜¾ç¤ºå¯¹è¯å†å²
  /model <name>  åˆ‡æ¢æ¨¡å‹ (flash/pro/pro3)
  /backend <name> åˆ‡æ¢åç«¯ (local/nexus/official)
  /status        æ˜¾ç¤ºå½“å‰çŠ¶æ€
  /save <file>   æ‰‹åŠ¨ä¿å­˜å¯¹è¯åˆ°æŒ‡å®šæ–‡ä»¶
  /load <file>   ä»æ–‡ä»¶åŠ è½½å¯¹è¯
  /paste         è¿›å…¥å¤šè¡Œè¾“å…¥æ¡†ï¼ˆCtrl+S å‘é€ï¼ŒCtrl+G å–æ¶ˆï¼›æ—  prompt_toolkit æ—¶ç”¨ . ç»“æŸï¼‰
  /img <path..> [text]  å‘é€å›¾ç‰‡ï¼ˆä¹Ÿæ”¯æŒç›´æ¥æ‹–æ‹½å›¾ç‰‡è·¯å¾„åˆ°è¾“å…¥ï¼‰
  /mode [normal|box]  åˆ‡æ¢è¾“å…¥æ¨¡å¼ï¼ˆé»˜è®¤ normalï¼‰

ğŸ”§ Function Calling (æ··åˆæ¨¡å¼):
  /tools                åˆ—å‡ºå½“å‰å¯ç”¨çš„å·¥å…·
  /tools add <name>     æ·»åŠ å·¥å…· (weather/search/calculator/bash)
  /tools remove <name>  ç§»é™¤å·¥å…·
  /tools clear          æ¸…ç©ºæ‰€æœ‰å·¥å…·
  /tools list           åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·
  /call <prompt>        å¼ºåˆ¶ä½¿ç”¨å®˜æ–¹APIè¿›è¡ŒFunction Calling

  ğŸ’¡ å¯ç”¨å·¥å…·åï¼Œä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°å®˜æ–¹APIåç«¯

å¿«æ·é”®:
  Ctrl+C         ä¸­æ–­å½“å‰æ“ä½œ
  Ctrl+D         é€€å‡ºç¨‹åºï¼ˆè‡ªåŠ¨ä¿å­˜ä¼šè¯å†å²ï¼‰
  ä¸Š/ä¸‹ç®­å¤´      æµè§ˆå†å²è¾“å…¥

è¾“å…¥æ¨¡å¼:
  normal: Enter å‘é€ï¼›è¾“å…¥æœ«å°¾ä¸º \\ æ—¶ç»­è¡Œ
  box:    å¤šè¡Œè¾“å…¥æ¡†ï¼›Enter æ¢è¡Œï¼›Ctrl+S å‘é€ï¼›Ctrl+G å–æ¶ˆ

è‡ªåŠ¨ä¿å­˜:
  é€€å‡ºæ—¶ä¼šè‡ªåŠ¨ä¿å­˜ä¼šè¯åˆ°: gchat_history_YYYYMMDD_HHMMSS.json
"""
    print(colored(help_text, Color.YELLOW))

def official_api_request(messages, model, tools=None, api_key=None):
    """ä½¿ç”¨Googleå®˜æ–¹APIå‘é€è¯·æ±‚ï¼ˆæ”¯æŒFunction Callingï¼‰"""
    if not api_key:
        api_key = os.environ.get("GEMINI_API_KEY", "")

    if not api_key:
        return None, "[é”™è¯¯] æœªè®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡\nè®¾ç½®æ–¹æ³•: export GEMINI_API_KEY='your-api-key'"

    # æ˜ å°„åˆ°å®˜æ–¹æ¨¡å‹å
    official_model = OFFICIAL_MODEL_MAP.get(model, "gemini-2.5-flash-lite")

    # æ„å»ºå®˜æ–¹APIæ ¼å¼çš„è¯·æ±‚
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{official_model}:generateContent?key={api_key}"

    # è½¬æ¢æ¶ˆæ¯æ ¼å¼ (OpenAI -> Gemini)
    contents = []
    for msg in messages:
        role = "user" if msg["role"] == "user" else "model"
        content = msg.get("content", "")
        if isinstance(content, str):
            contents.append({"role": role, "parts": [{"text": content}]})
        elif isinstance(content, list):
            parts = []
            for part in content:
                if part.get("type") == "text":
                    parts.append({"text": part.get("text", "")})
            if parts:
                contents.append({"role": role, "parts": parts})

    payload = {"contents": contents}

    # æ·»åŠ å·¥å…·å®šä¹‰
    if tools:
        payload["tools"] = [{"function_declarations": tools}]

    curl_cmd = [
        'curl', '-s', '-X', 'POST', url,
        '-H', 'Content-Type: application/json',
        '--max-time', '60',
        '-d', json.dumps(payload)
    ]

    try:
        result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=65)

        if result.returncode != 0:
            return None, f"[curlé”™è¯¯ {result.returncode}]: {result.stderr}"

        response_data = json.loads(result.stdout)

        # æ£€æŸ¥é”™è¯¯
        if "error" in response_data:
            error = response_data["error"]
            return None, f"[APIé”™è¯¯]: {error.get('message', json.dumps(error))}"

        # è§£æå“åº”
        candidates = response_data.get("candidates", [])
        if not candidates:
            return None, "[é”™è¯¯] æ— å“åº”å†…å®¹"

        content = candidates[0].get("content", {})
        parts = content.get("parts", [])

        for part in parts:
            # æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°è°ƒç”¨
            if "functionCall" in part:
                fc = part["functionCall"]
                return {
                    "type": "function_call",
                    "name": fc.get("name"),
                    "args": fc.get("args", {})
                }, None
            # æ™®é€šæ–‡æœ¬å“åº”
            if "text" in part:
                return {"type": "text", "content": part["text"]}, None

        return None, "[é”™è¯¯] æ— æ³•è§£æå“åº”"

    except subprocess.TimeoutExpired:
        return None, "[è¶…æ—¶]: å®˜æ–¹APIè¯·æ±‚è¶…è¿‡60ç§’"
    except json.JSONDecodeError as e:
        return None, f"[JSONè§£æé”™è¯¯]: {e}"
    except Exception as e:
        return None, f"[é”™è¯¯]: {e}"


def openai_tools_request(messages, model, tools, backend_config, retry=2):
    """å‘é€å¸¦å·¥å…·çš„è¯·æ±‚ï¼ˆOpenAI æ ¼å¼ï¼Œç”¨äº google åç«¯ï¼‰"""
    url = backend_config["url"]

    # è½¬æ¢å·¥å…·æ ¼å¼
    openai_tools = []
    for tool in tools:
        openai_tools.append({
            "type": "function",
            "function": {
                "name": tool["name"],
                "description": tool.get("description", ""),
                "parameters": tool.get("parameters", {"type": "object", "properties": {}})
            }
        })

    payload = {
        "model": model,
        "messages": normalize_messages_for_api(messages),
        "tools": openai_tools
    }

    curl_cmd = [
        'curl', '-s', '-X', 'POST', url,
        '-H', 'Content-Type: application/json',
        '--max-time', '120',
        '-d', json.dumps(payload)
    ]

    try:
        result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=125)

        if result.returncode != 0:
            return None, f"[curlé”™è¯¯ {result.returncode}]: {result.stderr}"

        response_data = json.loads(result.stdout)

        if "error" in response_data:
            return None, f"[APIé”™è¯¯]: {response_data['error'].get('message', str(response_data['error']))}"

        choice = response_data.get("choices", [{}])[0]
        message = choice.get("message", {})

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if "tool_calls" in message and message["tool_calls"]:
            tc = message["tool_calls"][0]
            func = tc.get("function", {})
            return {
                "type": "function_call",
                "name": func.get("name"),
                "args": json.loads(func.get("arguments", "{}"))
            }, None

        # æ™®é€šæ–‡æœ¬å“åº”
        content = message.get("content", "")
        if content:
            return {"type": "text", "content": content}, None

        return None, "[é”™è¯¯] æ— æ³•è§£æå“åº”"

    except subprocess.TimeoutExpired:
        return None, "[è¶…æ—¶]: è¯·æ±‚è¶…è¿‡120ç§’"
    except json.JSONDecodeError as e:
        return None, f"[JSONè§£æé”™è¯¯]: {e}\nå“åº”: {result.stdout[:300]}"
    except Exception as e:
        return None, f"[é”™è¯¯]: {e}"


def chat_request(messages, model, backend_config, retry=2, debug=False):
    """å‘é€èŠå¤©è¯·æ±‚ï¼ˆä½¿ç”¨curlï¼Œå…¼å®¹æ€§æœ€å¥½ï¼‰"""
    url = backend_config["url"]
    payload = {
        "model": model,
        "messages": normalize_messages_for_api(messages),
    }

    # æ„å»ºcurlå‘½ä»¤
    curl_cmd = [
        'curl', '-X', 'POST', url,
        '-H', 'Content-Type: application/json',
        '--max-time', '120',
        '--retry', str(retry),  # è‡ªåŠ¨é‡è¯•
        '--retry-delay', '2',    # é‡è¯•é—´éš”2ç§’
        '--connect-timeout', '30'  # è¿æ¥è¶…æ—¶30ç§’
    ]

    # è°ƒè¯•æ¨¡å¼æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    if not debug:
        curl_cmd.insert(1, '-s')  # é™é»˜æ¨¡å¼

    # å¦‚æœæœ‰API keyï¼Œæ·»åŠ Authorization header
    if "key" in backend_config:
        curl_cmd.extend(['-H', f'Authorization: Bearer {backend_config["key"]}'])

    # æ·»åŠ è¯·æ±‚ä½“
    curl_cmd.extend(['-d', json.dumps(payload)])

    try:
        # æ‰§è¡Œcurlå‘½ä»¤
        result = subprocess.run(
            curl_cmd,
            capture_output=True,
            text=True,
            timeout=125
        )

        if result.returncode != 0:
            stderr_msg = result.stderr.strip() if result.stderr else "ç½‘ç»œè¿æ¥å¤±è´¥"

            # é’ˆå¯¹ curl 35 é”™è¯¯ç»™å‡ºå…·ä½“å»ºè®®
            if result.returncode == 35:
                return (
                    f"[SSL/TLSé”™è¯¯ 35]: {stderr_msg}\n\n"
                    f"å¯èƒ½åŸå› :\n"
                    f"1. ç½‘ç»œç¯å¢ƒé—®é¢˜ï¼ˆWiFiä¸ç¨³å®šã€VPNå¹²æ‰°ï¼‰\n"
                    f"2. DNSè§£æé—®é¢˜\n"
                    f"3. é˜²ç«å¢™/å®‰å…¨è½¯ä»¶é˜»æ­¢\n\n"
                    f"å»ºè®®:\n"
                    f"- é‡è¯•å‡ æ¬¡ï¼ˆå¯èƒ½æ˜¯ç¬æ—¶ç½‘ç»œæ³¢åŠ¨ï¼‰\n"
                    f"- åˆ‡æ¢ç½‘ç»œï¼ˆWiFi â†’ æœ‰çº¿ æˆ– æ‰‹æœºçƒ­ç‚¹ï¼‰\n"
                    f"- å°è¯•: curl -v https://nexusai.aihang365.com\n"
                    f"- æˆ–ä½¿ç”¨æœ¬åœ°åç«¯: gchat -b local"
                )

            return f"[curlé”™è¯¯ {result.returncode}]: {stderr_msg}\næç¤º: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"

        # è§£æJSONå“åº”
        response_data = json.loads(result.stdout)

        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "error" in response_data:
            error = response_data["error"]
            error_msg = error.get("message", "")
            error_type = error.get("type", "")
            error_code = error.get("code", "")

            # æ„å»ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
            if error_msg:
                return f"[APIé”™è¯¯]: {error_msg}"
            elif error_type or error_code:
                return f"[APIé”™è¯¯]: {error_type or error_code}\nè¯¦æƒ…: {json.dumps(error, ensure_ascii=False)}"
                return f"[APIé”™è¯¯]: {json.dumps(error, ensure_ascii=False)}"

        # è¿”å›AIå›å¤
        return response_data["choices"][0]["message"]["content"]

    except subprocess.TimeoutExpired:
        return f"[è¶…æ—¶]: è¯·æ±‚è¶…è¿‡120ç§’"
    except json.JSONDecodeError as e:
        return f"[JSONè§£æé”™è¯¯]: {str(e)}\nå“åº”: {result.stdout[:200]}"
    except Exception as e:
        return f"[é”™è¯¯]: {str(e)}"

def resolve_model(model_input):
    """è§£ææ¨¡å‹åç§°"""
    return MODEL_ALIASES.get(model_input, model_input)


def chat_request_with_fallback(messages, model, backend_config, retry=2, debug=False):
    """å‘é€èŠå¤©è¯·æ±‚ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°å¤‡ç”¨æ¨¡å‹"""
    # ç¬¬ä¸€æ¬¡å°è¯•ï¼šä½¿ç”¨ä¸»æ¨¡å‹
    response = chat_request(messages, model, backend_config, retry=retry, debug=debug)

    # æ£€æŸ¥æ˜¯å¦å¤±è´¥ï¼ˆé”™è¯¯å“åº”ä»¥ [ å¼€å¤´ï¼‰
    if response.startswith("[") and model in FALLBACK_MODELS:
        fallback_model = FALLBACK_MODELS[model]
        print(f"\nâš ï¸  {model} è¯·æ±‚å¤±è´¥ï¼Œé™çº§åˆ° {fallback_model}...")
        response = chat_request(messages, fallback_model, backend_config, retry=retry, debug=debug)
        if not response.startswith("["):
            print(f"âœ… é™çº§æˆåŠŸï¼Œä½¿ç”¨ {fallback_model} å“åº”\n")

    return response

def auto_save_history(messages, model):
    """è‡ªåŠ¨ä¿å­˜ä¼šè¯å†å²åˆ°å½“å‰ç›®å½•"""
    if not messages or len(messages) == 0:
        return  # æ²¡æœ‰å¯¹è¯å†…å®¹ï¼Œä¸ä¿å­˜

    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"gchat_history_{timestamp}.json"

    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                "model": model,
                "messages": messages,
                "timestamp": timestamp
            }, f, ensure_ascii=False, indent=2)
        print(colored(f"ğŸ’¾ ä¼šè¯å·²è‡ªåŠ¨ä¿å­˜åˆ°: {filename}", Color.GREEN))
    except Exception as e:
        print(colored(f"âš ï¸  è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}", Color.RED))

def load_latest_history():
    """åŠ è½½å½“å‰ç›®å½•ä¸­æœ€æ–°çš„ä¼šè¯å†å²"""
    import glob

    history_files = glob.glob("gchat_history_*.json")
    if not history_files:
        return None, None, None

    # æŒ‰æ–‡ä»¶åæ’åºï¼ˆæ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ï¼Œè‡ªç„¶æ’åºå³å¯ï¼‰
    latest_file = sorted(history_files)[-1]

    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get("messages", []), data.get("model", "gemini-3-flash-preview"), latest_file
    except Exception as e:
        print(colored(f"âš ï¸  åŠ è½½ä¼šè¯å¤±è´¥: {e}", Color.RED))
        return None, None, None

def execute_function(name, args):
    """æ‰§è¡Œå‡½æ•°è°ƒç”¨ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    if name == "get_weather":
        city = args.get("city", "æœªçŸ¥")
        # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
        return {"city": city, "temperature": "15Â°C", "condition": "æ™´", "humidity": "45%"}
    elif name == "web_search":
        query = args.get("query", "")
        return {"results": [f"å…³äº '{query}' çš„æœç´¢ç»“æœ...", "æ›´å¤šå†…å®¹è¯·è®¿é—®æœç´¢å¼•æ“"]}
    elif name == "calculate":
        expr = args.get("expression", "0")
        try:
            # å®‰å…¨çš„æ•°å­¦è®¡ç®—
            import math
            allowed = {"sqrt": math.sqrt, "sin": math.sin, "cos": math.cos, "tan": math.tan,
                      "log": math.log, "exp": math.exp, "abs": abs, "round": round, "pow": pow}
            result = eval(expr, {"__builtins__": {}}, allowed)
            return {"expression": expr, "result": result}
        except Exception as e:
            return {"error": str(e)}
    elif name == "run_bash":
        command = args.get("command", "")
        try:
            result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=30)
            return {"command": command, "stdout": result.stdout, "stderr": result.stderr, "returncode": result.returncode}
        except Exception as e:
            return {"error": str(e)}
    else:
        return {"error": f"æœªçŸ¥å‡½æ•°: {name}"}


def interactive_mode(model, backend_name, continue_session=False):
    """äº¤äº’å¼å¤šè½®ä¼šè¯"""
    backend_config = BACKENDS[backend_name]
    model = resolve_model(model)
    messages = []
    loaded_file = None
    enabled_tools = []  # å½“å‰å¯ç”¨çš„å·¥å…·åˆ—è¡¨

    # å¦‚æœæ˜¯ç»§ç»­ä¼šè¯æ¨¡å¼ï¼Œå°è¯•åŠ è½½æœ€è¿‘çš„å†å²
    if continue_session:
        loaded_messages, loaded_model, loaded_file = load_latest_history()
        if loaded_messages:
            messages = loaded_messages
            if loaded_model:
                model = loaded_model
            print(colored("â—‹", Color.DIM) + f" Loaded: {colored(loaded_file, Color.DIM)}")
            print(colored("â—‹", Color.DIM) + f" Messages: {colored(f'{len(messages)} ({len(messages)//2} turns)', Color.DIM)}")
            print()

    print_header()
    # çŠ¶æ€å±‚ (Status Context)
    print(colored("â—‹", Color.DIM) + f" Model: {colored(model, Color.CYAN)}")
    print(colored("â—‹", Color.DIM) + f" Backend: {colored(backend_config['name'], Color.DIM)}")
    session_status = 'Continuing' if (continue_session and loaded_file) else 'New'
    print(colored("â—‹", Color.DIM) + f" Session: {colored(session_status, Color.GREEN)}")
    print()

    input_mode = 'normal'  # normal | box
    history = None
    if pt_prompt and FileHistory and sys.stdin.isatty():
        try:
            history = FileHistory(get_input_history_path())
        except Exception:
            history = None

    def prompt_text() -> str:
        if input_mode == 'box':
            return colored("nx ÏŸ[box] ", Color.CYAN + Color.BOLD)
        return colored("nx ÏŸ ", Color.CYAN + Color.BOLD)

    def read_user_message(force_box: bool = False, default_text: str = "") -> str | None:
        """è¯»å–ç”¨æˆ·è¾“å…¥ã€‚

        - normal: å•è¡Œ Enter å‘é€ï¼›å¦‚æœå†…å®¹å·²åŒ…å«æ¢è¡Œï¼ˆå¸¸è§äºç²˜è´´ï¼‰ï¼ŒEnter ç»§ç»­æ¢è¡Œï¼ŒCtrl+S å‘é€
        - box: å¤šè¡Œè¾“å…¥æ¡†ï¼›Enter æ¢è¡Œï¼ŒCtrl+S å‘é€ï¼ŒCtrl+G å–æ¶ˆ
        """
        use_box = force_box or (input_mode == 'box')

        if pt_prompt and KeyBindings and sys.stdin.isatty():
            kb = KeyBindings()
            cancel_token = "__CANCEL__"

            @kb.add('c-g')
            def _(event):
                event.app.exit(result=cancel_token)

            @kb.add('c-c')
            def _(event):
                buf = event.current_buffer
                if buf.text:
                    buf.reset()
                    return
                event.app.exit(result=cancel_token)

            @kb.add('c-s')
            def _(event):
                event.current_buffer.validate_and_handle()

            @kb.add('enter')
            def _(event):
                buf = event.current_buffer
                text = buf.text

                if text.endswith('\\'):
                    buf.delete_before_cursor(count=1)
                    buf.insert_text('\n')
                    return

                if use_box:
                    buf.insert_text('\n')
                    return

                if '\n' in text:
                    buf.insert_text('\n')
                    return

                buf.validate_and_handle()

            prompt_obj = PTANSI(prompt_text()) if PTANSI else prompt_text()
            try:
                text = pt_prompt(
                    prompt_obj,
                    default=default_text,
                    multiline=True,
                    key_bindings=kb,
                    history=history,
                    wrap_lines=True,
                )
            except KeyboardInterrupt:
                return None
            if text == cancel_token:
                return None
            return sanitize_terminal_paste(text)

        prompt = readline_safe_prompt(prompt_text())
        cont_prompt = readline_safe_prompt(colored("...> ", Color.BOLD))

        if use_box:
            print(colored("è¾“å…¥æ¡†æ¨¡å¼ï¼šè¾“å…¥å¤šè¡Œï¼Œå•ç‹¬ä¸€è¡Œè¾“å…¥ . ç»“æŸï¼›ç©ºå†…å®¹å–æ¶ˆã€‚", Color.YELLOW))
            lines: list[str] = []
            while True:
                try:
                    l = input(cont_prompt)
                except KeyboardInterrupt:
                    return None
                if l == '.':
                    break
                lines.append(l)
            text = "\n".join(lines)
            text = sanitize_terminal_paste(text)
            return text if text.strip() else None

        try:
            line = input(prompt)
        except KeyboardInterrupt:
            return None
        lines = []
        while True:
            if line.endswith('\\'):
                lines.append(line[:-1])
                try:
                    line = input(cont_prompt)
                except KeyboardInterrupt:
                    return None
                continue
            lines.append(line)
            break
        return sanitize_terminal_paste("\n".join(lines))

    def maybe_confirm_box(text: str) -> str | None:
        show = (input_mode == 'box') or ('\n' in text) or (len(text) >= 400)
        if not show:
            return text

        while True:
            print_box("å†…å®¹", text)
            ans = input("å‘é€ï¼Ÿ[Enter]=å‘é€, e=ç¼–è¾‘, c=å–æ¶ˆ > ").strip().lower()
            if ans in {'', 'y', 'yes'}:
                return text
            if ans in {'c', 'cancel', 'n', 'no'}:
                return None
            if ans in {'e', 'edit'}:
                edited = read_user_message(force_box=True, default_text=text)
                if edited is None:
                    return None
                text = edited
                continue

    while True:
        try:
            user_input_raw = read_user_message()
            if user_input_raw is None:
                continue

            user_input = user_input_raw.strip()

            if user_input == '/paste':
                pasted = read_user_message(force_box=True)
                if pasted is None:
                    continue
                user_input = pasted.strip()


            if not user_input:
                continue

            # å¤„ç†å‘½ä»¤
            if user_input.startswith('/'):
                cmd_parts = user_input[1:].split(maxsplit=1)
                cmd = cmd_parts[0].lower()
                cmd_arg = cmd_parts[1] if len(cmd_parts) > 1 else None

                if cmd in ['quit', 'q', 'exit']:
                    auto_save_history(messages, model)
                    print(colored("å†è§ï¼", Color.CYAN))
                    break
                elif cmd in ['help', 'h']:
                    print_help()
                elif cmd in ['clear', 'c']:
                    if messages:
                        msg_count = len(messages)
                        round_count = msg_count // 2
                        print(colored(f"ğŸ—‘ï¸  å·²æ¸…ç©º {msg_count} æ¡æ¶ˆæ¯ ({round_count} è½®å¯¹è¯)", Color.YELLOW))
                        print(colored("   ä¸Šä¸‹æ–‡å·²é‡ç½®ï¼Œå¼€å§‹æ–°çš„å¯¹è¯", Color.YELLOW))
                        messages = []
                    else:
                        print(colored("å¯¹è¯å†å²æœ¬æ¥å°±æ˜¯ç©ºçš„", Color.YELLOW))
                elif cmd == 'history':
                    if not messages:
                        print(colored("å¯¹è¯å†å²ä¸ºç©º", Color.YELLOW))
                    else:
                        for i, msg in enumerate(messages):
                            role = "You" if msg["role"] == "user" else "AI"
                            content = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
                            print(f"  [{i+1}] {role}: {content}")
                elif cmd == 'model':
                    if cmd_arg:
                        model = resolve_model(cmd_arg)
                        print(colored(f"æ¨¡å‹å·²åˆ‡æ¢åˆ°: {model}", Color.GREEN))
                    else:
                        print(f"å½“å‰æ¨¡å‹: {model}")
                        print(f"å¯ç”¨æ¨¡å‹: flash, pro, pro3")
                elif cmd == 'backend':
                    if cmd_arg and cmd_arg in BACKENDS:
                        backend_name = cmd_arg
                        backend_config = BACKENDS[backend_name]
                        print(colored(f"åç«¯å·²åˆ‡æ¢åˆ°: {backend_config['name']}", Color.GREEN))
                    else:
                        print(f"å½“å‰åç«¯: {backend_config['name']}")
                        print(f"å¯ç”¨åç«¯: {', '.join(BACKENDS.keys())}")
                elif cmd == 'status':
                    print(f"æ¨¡å‹: {model}")
                    print(f"åç«¯: {backend_config['name']}")
                    print(f"å¯¹è¯è½®æ•°: {len(messages) // 2}")
                    if enabled_tools:
                        print(f"å¯ç”¨å·¥å…·: {', '.join([t['name'] for t in enabled_tools])}")
                        if backend_config.get("supports_tools"):
                            print(colored("  ğŸ’¡ å½“å‰åç«¯æ”¯æŒ Function Calling", Color.GREEN))
                        else:
                            print(colored("  âš ï¸  å½“å‰åç«¯ä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œè¯·åˆ‡æ¢åˆ° google åç«¯", Color.YELLOW))
                    else:
                        print(f"å¯ç”¨å·¥å…·: æ— ")
                elif cmd == 'tools':
                    if not cmd_arg:
                        # åˆ—å‡ºå½“å‰å¯ç”¨çš„å·¥å…·
                        if enabled_tools:
                            print(colored("å½“å‰å¯ç”¨çš„å·¥å…·:", Color.GREEN))
                            for t in enabled_tools:
                                print(f"  ğŸ”§ {t['name']}: {t['description']}")
                        else:
                            print(colored("å½“å‰æ²¡æœ‰å¯ç”¨ä»»ä½•å·¥å…·", Color.YELLOW))
                            print("ä½¿ç”¨ /tools add <name> æ·»åŠ å·¥å…·ï¼Œå¯ç”¨: " + ", ".join(BUILTIN_TOOLS.keys()))
                    else:
                        parts = cmd_arg.split(maxsplit=1)
                        subcmd = parts[0].lower()
                        subarg = parts[1] if len(parts) > 1 else None

                        if subcmd == 'list':
                            print(colored("å¯ç”¨å·¥å…·:", Color.GREEN))
                            for name, tool in BUILTIN_TOOLS.items():
                                status = "âœ…" if any(t['name'] == tool['name'] for t in enabled_tools) else "  "
                                print(f"  {status} {name}: {tool['description']}")
                        elif subcmd == 'add':
                            if subarg and subarg in BUILTIN_TOOLS:
                                tool = BUILTIN_TOOLS[subarg]
                                if not any(t['name'] == tool['name'] for t in enabled_tools):
                                    enabled_tools.append(tool)
                                    print(colored(f"âœ… å·²æ·»åŠ å·¥å…·: {tool['name']}", Color.GREEN))
                                    print(colored("   ğŸ’¡ å¯ç”¨å·¥å…·åä¼šè‡ªåŠ¨ä½¿ç”¨å®˜æ–¹APIè¿›è¡ŒFunction Calling", Color.YELLOW))
                                else:
                                    print(colored(f"å·¥å…· {subarg} å·²ç»å¯ç”¨", Color.YELLOW))
                            else:
                                print(f"æœªçŸ¥å·¥å…·: {subarg}")
                                print("å¯ç”¨å·¥å…·: " + ", ".join(BUILTIN_TOOLS.keys()))
                        elif subcmd == 'remove':
                            if subarg:
                                tool = BUILTIN_TOOLS.get(subarg)
                                if tool:
                                    enabled_tools = [t for t in enabled_tools if t['name'] != tool['name']]
                                    print(colored(f"âŒ å·²ç§»é™¤å·¥å…·: {tool['name']}", Color.YELLOW))
                                else:
                                    print(f"æœªçŸ¥å·¥å…·: {subarg}")
                            else:
                                print("ç”¨æ³•: /tools remove <name>")
                        elif subcmd == 'clear':
                            enabled_tools = []
                            print(colored("å·²æ¸…ç©ºæ‰€æœ‰å·¥å…·", Color.YELLOW))
                        else:
                            print(f"æœªçŸ¥å­å‘½ä»¤: {subcmd}")
                            print("ç”¨æ³•: /tools [list|add|remove|clear]")
                elif cmd == 'call':
                    # å¼ºåˆ¶ä½¿ç”¨å®˜æ–¹APIè¿›è¡ŒFunction Calling
                    if not cmd_arg:
                        print("ç”¨æ³•: /call <æç¤ºè¯>")
                        continue

                    if not enabled_tools:
                        print(colored("âš ï¸  æ²¡æœ‰å¯ç”¨ä»»ä½•å·¥å…·ï¼Œè¯·å…ˆä½¿ç”¨ /tools add <name> æ·»åŠ å·¥å…·", Color.YELLOW))
                        continue

                    print(colored(f"ğŸ”§ ä½¿ç”¨å®˜æ–¹APIè¿›è¡ŒFunction Calling...", Color.CYAN))
                    messages.append({"role": "user", "content": cmd_arg})

                    result, error = official_api_request(messages, model, enabled_tools)
                    if error:
                        print(colored(error, Color.RED))
                        messages.pop()  # ç§»é™¤å¤±è´¥çš„æ¶ˆæ¯
                        continue

                    if result["type"] == "function_call":
                        fc_name = result["name"]
                        fc_args = result["args"]
                        print(colored(f"ğŸ“ å‡½æ•°è°ƒç”¨: {fc_name}({json.dumps(fc_args, ensure_ascii=False)})", Color.YELLOW))

                        # æ‰§è¡Œå‡½æ•°
                        fc_result = execute_function(fc_name, fc_args)
                        print(colored(f"ğŸ“¤ å‡½æ•°ç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}", Color.GREEN))

                        # è®°å½•åˆ°å†å²
                        messages.append({"role": "assistant", "content": f"[è°ƒç”¨å‡½æ•° {fc_name}]\nå‚æ•°: {json.dumps(fc_args, ensure_ascii=False)}\nç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}"})
                    else:
                        print(colored("AI>", Color.CYAN))
                        print(result["content"])
                        messages.append({"role": "assistant", "content": result["content"]})
                    print()
                elif cmd == 'save':
                    if cmd_arg:
                        try:
                            with open(cmd_arg, 'w', encoding='utf-8') as f:
                                json.dump({"model": model, "messages": messages}, f, ensure_ascii=False, indent=2)
                            print(colored(f"å¯¹è¯å·²ä¿å­˜åˆ°: {cmd_arg}", Color.GREEN))
                        except Exception as e:
                            print(colored(f"ä¿å­˜å¤±è´¥: {e}", Color.RED))
                    else:
                        print("ç”¨æ³•: /save <æ–‡ä»¶å>")
                elif cmd == 'load':
                    if cmd_arg:
                        try:
                            with open(cmd_arg, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                messages = data.get("messages", [])
                                model = data.get("model", model)
                            print(colored(f"å¯¹è¯å·²åŠ è½½ï¼Œå…± {len(messages)} æ¡æ¶ˆæ¯", Color.GREEN))
                        except Exception as e:
                            print(colored(f"åŠ è½½å¤±è´¥: {e}", Color.RED))
                    else:
                        print("ç”¨æ³•: /load <æ–‡ä»¶å>")
                elif cmd == 'mode':
                    if not cmd_arg:
                        input_mode = 'box' if input_mode == 'normal' else 'normal'
                    else:
                        arg = cmd_arg.strip().lower()
                        if arg in {'normal', 'n'}:
                            input_mode = 'normal'
                        elif arg in {'box', 'b'}:
                            input_mode = 'box'
                        else:
                            print(colored("ç”¨æ³•: /mode [normal|box]", Color.YELLOW))
                            continue
                    print(colored(f"è¾“å…¥æ¨¡å¼å·²åˆ‡æ¢åˆ°: {input_mode}", Color.GREEN))
                elif cmd in {'img', 'image'}:
                    try:
                        parts = shlex.split(user_input, posix=True)
                    except ValueError as e:
                        print(colored(f"å‚æ•°è§£æå¤±è´¥: {e}", Color.RED))
                        continue

                    args = parts[1:]
                    if not args:
                        print(colored("ç”¨æ³•: /img <å›¾ç‰‡è·¯å¾„...> [æè¿°æ–‡æœ¬]", Color.YELLOW))
                        continue

                    image_paths: list[Path] = []
                    text_parts: list[str] = []
                    for tok in args:
                        p = Path(tok).expanduser()
                        if is_image_file(p):
                            image_paths.append(p)
                        else:
                            text_parts.append(tok)

                    if not image_paths:
                        print(colored("æœªæ£€æµ‹åˆ°æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒ png/jpg/jpeg/webp/gif ç­‰ï¼‰", Color.YELLOW))
                        continue

                    user_text = " ".join(text_parts).strip() or "è¯·æè¿°è¿™å¼ å›¾ç‰‡ã€‚"
                    confirmed_text = maybe_confirm_box(user_text)
                    if confirmed_text is None:
                        continue

                    user_message = {
                        "role": "user",
                        "content": [{"type": "text", "text": confirmed_text}] + [
                            {"type": "image_file", "path": str(p)} for p in image_paths
                        ],
                    }
                    messages.append(user_message)

                    print(colored("AI>", Color.CYAN))
                    response = chat_request_with_fallback(messages, model, backend_config)
                    print(response)
                    print()
                    messages.append({"role": "assistant", "content": response})
                else:
                    print(colored(f"æœªçŸ¥å‘½ä»¤: /{cmd}ï¼Œè¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©", Color.RED))
                continue

            # å›¾ç‰‡ï¼šæ”¯æŒç›´æ¥æ‹–æ‹½å›¾ç‰‡è·¯å¾„åˆ°è¾“å…¥æ¡†
            cleaned_text, image_paths = extract_local_image_paths(user_input)
            if image_paths:
                user_text = cleaned_text or "è¯·æè¿°è¿™å¼ å›¾ç‰‡ã€‚"
                confirmed_text = maybe_confirm_box(user_text)
                if confirmed_text is None:
                    continue
                messages.append({
                    "role": "user",
                    "content": [{"type": "text", "text": confirmed_text}] + [
                        {"type": "image_file", "path": str(p)} for p in image_paths
                    ],
                })
            else:
                confirmed_text = maybe_confirm_box(user_input)
                if confirmed_text is None:
                    continue
                messages.append({"role": "user", "content": confirmed_text})

            # å‘é€è¯·æ±‚ - æ··åˆè·¯ç”±é€»è¾‘
            print(colored("AI>", Color.CYAN))

            if enabled_tools and backend_config.get("supports_tools"):
                # æœ‰å·¥å…·ä¸”åç«¯æ”¯æŒæ—¶ï¼Œä½¿ç”¨å·¥å…·è°ƒç”¨
                if backend_name == "google":
                    # google åç«¯ä½¿ç”¨ OpenAI æ ¼å¼
                    result, error = openai_tools_request(messages, model, enabled_tools, backend_config)
                else:
                    # official åç«¯ä½¿ç”¨ Gemini åŸç”Ÿæ ¼å¼
                    result, error = official_api_request(messages, model, enabled_tools)

                if error:
                    print(colored(error, Color.RED))
                    messages.pop()  # ç§»é™¤å¤±è´¥çš„æ¶ˆæ¯
                    continue

                if result["type"] == "function_call":
                    fc_name = result["name"]
                    fc_args = result["args"]
                    print(colored(f"ğŸ“ å‡½æ•°è°ƒç”¨: {fc_name}({json.dumps(fc_args, ensure_ascii=False)})", Color.YELLOW))

                    # æ‰§è¡Œå‡½æ•°
                    fc_result = execute_function(fc_name, fc_args)
                    print(colored(f"ğŸ“¤ å‡½æ•°ç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}", Color.GREEN))

                    # è®°å½•åˆ°å†å²
                    response = f"[è°ƒç”¨å‡½æ•° {fc_name}]\nå‚æ•°: {json.dumps(fc_args, ensure_ascii=False)}\nç»“æœ: {json.dumps(fc_result, ensure_ascii=False)}"
                else:
                    response = result["content"]
                    print(response)
            else:
                # æ— å·¥å…·æˆ–åç«¯ä¸æ”¯æŒæ—¶ä½¿ç”¨æ™®é€šè¯·æ±‚
                response = chat_request_with_fallback(messages, model, backend_config)
                print(response)

            print()

            # æ·»åŠ AIå›å¤åˆ°å†å²
            messages.append({"role": "assistant", "content": response})

        except KeyboardInterrupt:
            print("\n" + colored("(ä½¿ç”¨ /quit é€€å‡º)", Color.YELLOW))
        except EOFError:
            print()
            auto_save_history(messages, model)
            print(colored("å†è§ï¼", Color.CYAN))
            break

def single_prompt(prompt, model, backend_name):
    """å•æ¬¡æé—®æ¨¡å¼"""
    backend_config = BACKENDS[backend_name]
    model = resolve_model(model)
    messages = [{"role": "user", "content": prompt}]
    response = chat_request_with_fallback(messages, model, backend_config)
    print(response)

def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    print("å¯ç”¨æ¨¡å‹:")
    print("  flash   -> gemini-3-flash-preview (æœ€æ–° 3.0 Flash) â­ æ¨è")
    print("  flash3  -> gemini-3-flash-preview (åŒä¸Š)")
    print("  flash2  -> gemini-2.5-flash (æ—§ç‰ˆ Flash)")
    print("  pro     -> gemini-2.5-pro (Pro)")
    print("  pro3    -> gemini-3.0-pro (3.0 Pro)")
    print()
    print("å¯ç”¨åç«¯:")
    for name, config in BACKENDS.items():
        tools_support = "âœ… æ”¯æŒFunction Calling" if config.get("supports_tools") else ""
        print(f"  {name:8} -> {config['name']} {tools_support}")
    print()
    print("å¯ç”¨å·¥å…· (ç”¨äºFunction Calling):")
    for name, tool in BUILTIN_TOOLS.items():
        print(f"  {name:12} -> {tool['description']}")

def main():
    parser = argparse.ArgumentParser(
        description="Gemini Chat CLI - å¤šè½®ä¼šè¯å‘½ä»¤è¡Œå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  gchat                    å¼€å¯æ–°å¯¹è¯
  gchat -c                 ç»§ç»­ä¸Šæ¬¡å¯¹è¯ï¼ˆè‡ªåŠ¨åŠ è½½æœ€è¿‘ä¼šè¯ï¼‰
  gchat -m pro             ä½¿ç”¨proæ¨¡å‹
  gchat -p "è§£é‡Šé‡å­è®¡ç®—"   å•æ¬¡æé—®
  gchat --backend nexus    ä½¿ç”¨NexusAIåç«¯
        """
    )

    parser.add_argument('-m', '--model', default='pro3',
                        help='æ¨¡å‹åç§° (pro3/flash3/pro/flashï¼Œé»˜è®¤: pro3)')
    parser.add_argument('-p', '--prompt',
                        help='å•æ¬¡æé—®ï¼ˆä¸è¿›å…¥äº¤äº’æ¨¡å¼ï¼‰')
    parser.add_argument('-c', '--continue', dest='continue_session', action='store_true',
                        help='ç»§ç»­ä¸Šæ¬¡ä¼šè¯ï¼ˆè‡ªåŠ¨åŠ è½½æœ€è¿‘çš„å†å²è®°å½•ï¼‰')
    parser.add_argument('-b', '--backend', default='google',
                        choices=BACKENDS.keys(),
                        help='åç«¯é€‰æ‹© (é»˜è®¤: google)')
    parser.add_argument('--list-models', action='store_true',
                        help='åˆ—å‡ºå¯ç”¨æ¨¡å‹å’Œåç«¯')

    args = parser.parse_args()

    if args.list_models:
        list_models()
        return

    if args.prompt:
        single_prompt(args.prompt, args.model, args.backend)
    else:
        interactive_mode(args.model, args.backend, continue_session=args.continue_session)

if __name__ == "__main__":
    main()
